{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"STACK | Online assessment STACK is the world-leading open-source online assessment system for mathematics and STEM. It is available for Moodle, ILIAS and as an integration through LTI. Why use STACK? Algebraic answers Students can answer algebraic expressions, like \\(x^2+y\\), and answers are graded based on mathematical properties. Separate validation and assessment Answers are validated before they are marked, so students are not penalised for poor programming skills. Specific feedback Students are given feedback that refers to their specific answer and mistake, as if marked by hand. Randomisation STACK can generate random questions so students are shown different variants of questions, and can repeat quizzes with new variants. Language support STACK is available in most European languages and many more, including Hebrew and Japanese. Open-source STACK is free to use and is developed by educators like yourself. Contributions are welcomed and encouraged. Learn more Get Started Who uses STACK? STACK is used by universities, commercial partners, developers and more, in over 15 countries. To read about the many ways STACK is used around the world, please visit our Case Studies page. Case Studies Training and Events We host regular training workshops and a yearly international STACK conference. To sign up for one of our future events, or see materials from our past events, go to our Training and Events page. Training and Events Documentation STACK has extensive documentation available locally through GitHub and online. To get started, see the Authoring quick start or the self-contained \"Getting started with STACK\" guide . Documentation","title":"Home"},{"location":"About/","text":"About STACK STACK is an online assessment system for mathematics and STEM, designed to enable students to answer questions with a mathematical expression, such as a polynomial. It is available for Moodle and ILIAS , and as an integration through LTI . STACK helps students learn from their mistakes through specific feedback. Computer Algebra Support STACK uses the Computer Algebra System Maxima to evaluate expressions. Mathematical answers: questions are not limited to multiple choice. Randomise questions so different students see different variants of a quiz. Graphical support: make your questions stand out by integrating Maxima plots, JSXGraphs or Google Charts. Validation of answers Before answers are graded, students confirm their answer is interpreted correctly by the system. Invalid answers, like ones with mismatched brackets, are rejected. Fair: students are not penalised for poor computer skills. Flexible: the teacher decides what a valid answer looks like. Intelligent marking Teachers write grading trees that mark answers based on mathematical properties, like \"is it factored?\" Specific feedback tailored to each student's answer. Multipart questions with follow-through marking. Give-example style questions with many correct answers. Diverse question types involving scientific units, numerical accuracy, line-by-line reasoning and more. Open-source As an open-source project, users help improve STACK by adding features, translations, bug reports and more. Many users share STACK materials, for example through the ABACUS material bank. Credits and contributions ABACUS material bank Trusted user base STACK is trusted by many respected institutions. More users","title":"About"},{"location":"About/#about-stack","text":"STACK is an online assessment system for mathematics and STEM, designed to enable students to answer questions with a mathematical expression, such as a polynomial. It is available for Moodle and ILIAS , and as an integration through LTI . STACK helps students learn from their mistakes through specific feedback.","title":"About STACK"},{"location":"About/#validation-of-answers","text":"Before answers are graded, students confirm their answer is interpreted correctly by the system. Invalid answers, like ones with mismatched brackets, are rejected. Fair: students are not penalised for poor computer skills. Flexible: the teacher decides what a valid answer looks like.","title":"Validation of answers"},{"location":"About/#intelligent-marking","text":"Teachers write grading trees that mark answers based on mathematical properties, like \"is it factored?\" Specific feedback tailored to each student's answer. Multipart questions with follow-through marking. Give-example style questions with many correct answers. Diverse question types involving scientific units, numerical accuracy, line-by-line reasoning and more.","title":"Intelligent marking"},{"location":"About/#open-source","text":"As an open-source project, users help improve STACK by adding features, translations, bug reports and more. Many users share STACK materials, for example through the ABACUS material bank. Credits and contributions ABACUS material bank","title":"Open-source"},{"location":"About/#trusted-user-base","text":"STACK is trusted by many respected institutions. More users","title":"Trusted user base"},{"location":"GetStarted/","text":"I am a... Teacher Explore STACKs features by visiting our Demo site. If you have STACK installed and want to write your first question, see our question authoring quick start guide. Demo site \u2003 Quick start guide Student Read the information for students on our documentation, including accessibility and FAQ, or get used to STACK syntax with our syntax quiz. Info for students \u2003 Syntax quiz Site administrator STACK can be installed on Moodle or ILIAS, or integrated into other Learning Management Systems via LTI. Install STACK \u2003 Integrate via LTI Developer STACK is open-source and welcomes contributions: added features, integrations, translations, bug reports and more. Contribute to STACK","title":"Get Started"},{"location":"Training_and_events/","text":"Training and Events We regularly host conferences and training workshops for STACK. You can find videos from previous events on our YouTube channel. STACK videos Upcoming events Here is a list of upcoming events: Date Title Location Description 26-27 April 2021 The 4th International STACK Conference TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. \"It had a very good mix of theory and practical applicatons.\" \"It told me exactly what I needed to get started on writing STACK questions, while also giving some feedback on why we use STACK.\" Past events A list of past STACK workshops and conferences: Date Title Location Description 20 July 2020 10:00-12:00 BST Workshop: Getting started with STACK Online. Course page - getting started 20-07 Learn about the features of STACK and write your first STACK question with experts on hand to help. 3 July 2020 14:00-16:00 BST\u2003 Workshop: addressing common student errors \u2003 Online. Course page - student errors \u2003 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Week of 22 June 2020 EAMS 2020 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. 19 June 2020 10:00-12:00 BST Workshop: quality questions and assessing proof Online. Course page - quality questions Learn about advanced features of STACK that help to make sure your questions work reliably, and get tips from experienced authors on how to write polished questions. In the second half, learn about ways to assess proof using STACK. 15 June 2020 10:00-15:00 BST Workshop: getting started with STACK Online. Course page - getting started Hear from some experienced users about how they use STACK in variety of courses, then write your first STACK question with experts on hand to help. 27 April 2020 The 3rd International STACK Conference Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. 29-30 April 2019 Putting educational research into practice in HE Mathematics and Statistics teaching The University of Edinburgh, Edinburgh, UK Putting research into practice conference website Day 1: Putting educational research into practice in HE Mathematics and Statistics teaching. Day 2: The 2nd International STACK Conference. 15-16 November 2018 The 1st International STACK Conference Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Training and Events"},{"location":"Training_and_events/#training-and-events","text":"We regularly host conferences and training workshops for STACK. You can find videos from previous events on our YouTube channel. STACK videos","title":"Training and Events"},{"location":"Training_and_events/#upcoming-events","text":"Here is a list of upcoming events: Date Title Location Description 26-27 April 2021 The 4th International STACK Conference TTK University of Applied Sciences, Tallinn, Estonia stack21.edu.ee This conference aims to act as a forum for the exchange of experience, ideas and research associated with implementing STACK. The target group is academics who teach undergraduate and postgraduate STEM courses in higher education institutions. \"It had a very good mix of theory and practical applicatons.\" \"It told me exactly what I needed to get started on writing STACK questions, while also giving some feedback on why we use STACK.\"","title":"Upcoming events"},{"location":"Training_and_events/#past-events","text":"A list of past STACK workshops and conferences: Date Title Location Description 20 July 2020 10:00-12:00 BST Workshop: Getting started with STACK Online. Course page - getting started 20-07 Learn about the features of STACK and write your first STACK question with experts on hand to help. 3 July 2020 14:00-16:00 BST\u2003 Workshop: addressing common student errors \u2003 Online. Course page - student errors \u2003 Gain insight into common student errors based on mathematics education research, and get practical experience of using STACK to detect and give feedback on errors. Week of 22 June 2020 EAMS 2020 Online. eams.ncl.ac.uk There will be various sessions of interest to STACK users at this conference. 19 June 2020 10:00-12:00 BST Workshop: quality questions and assessing proof Online. Course page - quality questions Learn about advanced features of STACK that help to make sure your questions work reliably, and get tips from experienced authors on how to write polished questions. In the second half, learn about ways to assess proof using STACK. 15 June 2020 10:00-15:00 BST Workshop: getting started with STACK Online. Course page - getting started Hear from some experienced users about how they use STACK in variety of courses, then write your first STACK question with experts on hand to help. 27 April 2020 The 3rd International STACK Conference Online. 3rd International STACK Conference Website The aim of the conference is to provide a platform for academics, researchers, and scholars, to address common challenges, share knowledge and ideas as well as recent trends and brainstorm creative solutions in the field of STACK. 29-30 April 2019 Putting educational research into practice in HE Mathematics and Statistics teaching The University of Edinburgh, Edinburgh, UK Putting research into practice conference website Day 1: Putting educational research into practice in HE Mathematics and Statistics teaching. Day 2: The 2nd International STACK Conference. 15-16 November 2018 The 1st International STACK Conference Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg, F\u00fcrth, Germany www.stack-konferenz.de The mission of the Conference is to offer a forum for the STACK Community, to exchange ideas about possibilities and challenges in creating questions, to get closer to solving technical questions and to shape the future of STACK.","title":"Past events"},{"location":"CaseStudies/","text":"Who uses STACK? STACK has users all over the world. To highlight some of the ways STACK is used and developed around the world, we have written a number of case studies. Explore the map, or see the full list of case studies below. stars Case studies place Other key users 2019 In 2019, a project was carried out to write an initial collection of STACK case studies. The case studies were edited by Malthe Sporring and Chris Sangwin, and funded by CATE. Case Studies Booklet Developing a Fully Online Course \"Fundamentals of Algebra and Calculus\" is a fully online course that uses STACK. STACK for a Physics Textbook Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook. Adaptive Self-learning Exercises The Ruhr-Universit\u00e4t Bochum uses STACK in online courses designed for self-study. Some questions are adaptive, and guide students through complex tasks. A Flick Interface for Maths Input Developers at Nagoya University are building a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Innovating Education in Maseno, Kenya IDEMS international is working with Maseno University to implement online assessment for their mathematics courses. optes: Optimising Self-study With STACK The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills. Technical Integration of STACK Into ILIAS STACK was integrated into the ILIAS learning management system to support projects for learning content. STACK at Scale: The Open University The Open University uses STACK for large-scale online courses. STACK for Engineering Mathematics and the Abacus Material Bank Aalto University uses STACK for their Engineering Mathematics courses, and they have also developed the material bank Abacus. Promoting STACK Across Disciplines at Loughborough University At Loughborough University, STACK has been implemented across many disciplines. Institutional Support for STACK in Edinburgh The University of Edinburgh has in-house support for online assessment, mostly with STACK, for most year one and two mathematics modules, and many more.","title":"Overview"},{"location":"CaseStudies/#who-uses-stack","text":"STACK has users all over the world. To highlight some of the ways STACK is used and developed around the world, we have written a number of case studies. Explore the map, or see the full list of case studies below. stars Case studies place Other key users","title":"Who uses STACK?"},{"location":"CaseStudies/#2019","text":"In 2019, a project was carried out to write an initial collection of STACK case studies. The case studies were edited by Malthe Sporring and Chris Sangwin, and funded by CATE. Case Studies Booklet","title":"2019"},{"location":"CaseStudies/2019/ABACUS/","text":"STACK for Engineering Mathematics and the Abacus Material Bank Aalto University Antti Rasila, Guangdong Technion - Israel Institute of Technology Abstract Since 2006, Aalto University has been using STACK to run online assessments within their Engineering Mathematics courses. Initially, the University was running a STACK version developed in-house specifically for the University, but this was later merged back into the main STACK branch in version 3.0. After receiving funding, the material bank Abacus was created, with the purpose of helping institutions collaborate and share STACK questions. The project's agreement was written in a way that ensured question authors kept their copyright, while still encouraging collaboration. Abacus has 30 members and its courses cover most of undergraduate mathematics and many parts of physics. Motivation The MatTa group (\"Matematiikkaa tietokoneavusteisesti\"; \"mathematics by using computers\") was founded in 1990s by lecturer Emeritus Simo K. Kivel\u00e4 at the Department of Mathematics and Systems Analysis at Aalto University, formerly known as Helsinki University of Technology. The purpose of the group was to investigate the use of computers and information technology to teach engineering mathematics. Initially, the projects involved, for example, using visualisations, multimedia and symbolic computation to make mathematical content more interesting and accessible for students. The group also produced a number of free Finnish language electronic lecture notes with interactive content and a substantial database of traditional pen and paper exercise assignments called Euler. In 2006, the group started to take interest in automatic assessment, as they believed computer-aided methodologies could achieve a practical impact in teaching activities there. There was also hope at the University that Computer Aided Assessment could reduce the number of students assistants required to grade homework, both to save cost and because a sufficient number of qualified graders was not always available. Initially, the group focused on the Maple T.A. system, however it was found lacking in several aspects. The most important of these were performance issues and an incompatibility with various browsers, in particular ones available for the Linux operating system. The high licensing fees were also a problem, as they could undo all the savings that the University hoped to achieve by using the system. In spring of 2006, the group started gaining interest in STACK, which has an open source license. This license would allow the University to use its in-house software development skills to improve the platform where needed, and it would also guarantee that licence fees would not be imposed in the future. After deciding to use STACK, which was running its standalone version 1.x at the time, the group spent the summer of 2006 modifying the software to better suit the University's needs. This included replacing the rendering code of mathematical formulas to support browsers other than Microsoft Internet Explorer, translating the software to Finnish and a Shibboleth based integration with the Finnish national Haka single-sign-in system. Implementing STACK Figure: An interactive STACK question from Aalto University's \"Multivariable Calculus\" course, where students drag points along a contour line. After modifying the system, the University started testing STACK. The initial test was with the university's Basic Course in Engineering Mathematics KP3. A. Rasila wrote four STACK assignments for each week of the course, all of which were relatively simple questions involving numerical or algebraic input. The system had numerous small technical issues, but the students were generally happy with the system as evidenced both by student feedback and general usage statistics [1]. Encouraged by the positive results, it was decided to test the system more comprehensively to convince the teaching community that automatic assessment was worth of the effort in teaching engineering mathematics. It was important to show that the online assessment could be used by teachers with little programming skill, and that it would not cause a large increase in their workload. This was crucial for the long-term success of the project, as MatTa's previously developed materials were often only used by a handful of teachers, most of whom where developers themselves. Furthermore, the group needed to demonstrate that the system had real cost savings, as well as good learning outcomes compared to traditional types of assignments. The University set up an experimental course \"Discrete Mathematics\", where STACK would form a significant portion of the final grade [2]. Following the positive results of this course, the use of STACK began to spread at the University, and within three years, most basic courses in Engineering Mathematics at Aalto University were using STACK. STACK Developments A key ingredient in the success of STACK at Aalto University were the in-house developments by programmer Matti Harjula, also wrote his Master\u2019s Thesis on this work [3]. His initial work included analysing the data of the first 2006 experiment and further developing the system to address any shortcomings. His project was successful, as it led to a system that many lecturers at the department were willing to use, and no major issues were identified in the subsequent use of the system. However, it also led to a new problem. Independently from Aalto University, the British STACK developers had been developing STACK 2.0, which was very different from the 1.x series Aalto University had been using for their work. The in-house developments by Aalto University were not easily implemented into STACK 2.0, but merging the Aalto University code back into the trunk of STACK was still necessary for a number of reasons. Firstly, a unified code base would speed up the overall development of STACK, and the Department at Aalto University did not intend to permanently commit many resources to maintaining the system. Secondly, there was interest from other Finnish universities to try the system, however they preferred to use the \u201cofficial\u201d British version of STACK, which would prevent them from using the materials developed at Aalto University. Because of this, the Finnish and British developers agreed to join forces in combining their work into STACK 3.0. During the STACK 3.0 merge, experimental features of STACK were also being added to the Aalto University version, as documented in section 7.8 of [4]. These features were related to several pedagogical ideas, detailed in [5,6,7]. Creating Abacus There were two key advancements in 2015. Firstly, STACK 3.0 was completed and Aalto University had finalised their plans to the deploy the system as a replacement to their old in-house version. Since the University was now using the official STACK version, it was easier to collaborate with other Universities on STACK material. Secondly, the consortium of the seven Finnish technology universities called for proposals in developing collaborative practices in education. A draft proposal for joint development of electronic materials for mathematics education was proposed and selected as a pilot project with over half a million euros of funding. A. Rasila was chosen as the national coordinator of this project, which become known as the Abacus consortium [8]. Figure: The Abacus logo. Abacus is a database of teaching materials, mainly STACK questions, covering most basic topics in undergraduate mathematics. Its mission statement is to help lecturers find high quality and free learning materials, achieved through facilitating the sharing of online teaching resources between institutions. National and international collaboration is at the heart of the project, as it helps standardise the platform, minimise the necessary contribution of each institution and contribute to the overall market share of the platform. Language differences between courses is not a concern, since adding translations to individual questions are almost trivial compared to the expense of actually programming the mathematics e-content. In drafting the initial consortium agreement, Abacus drew from two other related projects, namely a 2009 e-learning collaboration project with the Bavarian Virtual University VHB, which was funded by the later discontinued Finnish Virtual University, and the MatTa material bank Euler. Fair Use In projects largely developed through public and institutional funding, fair use is a common problem. Some partners may feel they are contributing more than the rest, and hence will not be interested in collaboration and instead push for in-house development. Furthermore, collaborators who develop materials without being paid are often unhappy when someone else makes even minor monetary gains from their work, which has led to a widespread use of non-commercial licenses for academic work. While understandable, these restrictions hinder the acceptance of platforms like Abacus, and lead to divisions in the community. Furthermore, non-commercial licenses can be confusing, as the exact nature of commercial activity is not clearly defined in academia. For example, is \"free\" work done by a salaried lecturer commercial use? Finally, it can be necessary for institutions to share the sources of assignments due to international differences in notation, course content and language. On the other hand, a pure open source model is not particularly attractive for e-assessment materials, since students should not be able to search online for the teachers' answers. To solve these problems, the Abacus consortium agreement was written such that there are no strict legal restrictions on what kind of institutions can join the consortium or what kinds of materials can be included. The materials are shared in a way such that each partner gets substantial rights to develop them based on a license similar to open source, but is not allowed to share the source code with third parties. The original developers retain their copyright of the materials and are allowed to give them other licenses besides the one required by Abacus. Since new members are reviewed by the consortium's steering group and are required to make a one-time contribution to the consortium, the agreement encourages collaboration and guarantees that existing partners benefit from the growth of the consortium. Outlook As of July 2019, the Abacus consortium consists of 30 members, 17 of which are from Finland, as well as three from Estonia and two from both Germany and Norway. Other countries present in the consortium are China, France, Ireland, Portugal, Ukraine, and the United Kingdom. There are ongoing discussions with several other potential partners, mainly from Europe. The database currently contains problem assignments for most bachelor level courses in mathematics, as well as a substantial number of physics assignments. Although Abacus accepts contributions in any language, most materials are available in English. Translations of the remaining Finnish-only materials are ongoing, and are expected to be completed in 2020. References [1] A. Rasila, M. Harjula, and K. Zenger. Automatic assessment of mathematics exercises: Experiences and future prospects. In ReekTori 2007: Symposium of Engineering Education, 70-80. Helsinki University of Technology, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2007. [2] A. Rasila, L. Havola, H. Majander, and J. Malinen. Automatic assessment in engineering mathematics: evaluation of the impact. In ReekTori 2010: Symposium of Engineering Education. Aalto University, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2010. [3] M. Harjula. Mathematics exercise system with automatic assessment. Master's thesis, Helsinki University of Technology, 2008. [4] C. J. Sangwin. Computer Aided Assessment of Mathematics. Oxford University Press, Oxford, UK, 2013. [5] H. Majander and A. Rasila. Tutkimus suuntaamassa 2010-luvun matemaattisten aineiden opetusta, Experiences of continuous formative assessment in engineering mathematics, 197-214. Tampereen yliopistopaino Oy - Juvenes Print, 2011. [6] A. Rasila, J. Malinen, and H. Tiitu. Automatic assement and conceptual understanding. Teaching Mathematics and its Applications, 34(3):149-159, 2015. [7] T. Pelkola, A. Rasila, and C. J. Sangwin. Investigating Bloom's learning for mastery in mathematics with online assessment. Informatics in Education, 17(2), 363-380, 2018. [8] A. Rasila. E-assessment material bank abacus. In Proceedings of EDILEARN16, 8th Annual International Conference on Education and New Learning Technologies, July 2016. STACK at Scale: The Open University Promoting STACK Across Disciplines at Loughborough University","title":"STACK for Engineering Mathematics and the Abacus Material Bank"},{"location":"CaseStudies/2019/ABACUS/#stack-for-engineering-mathematics-and-the-abacus-material-bank","text":"","title":"STACK for Engineering Mathematics and the Abacus Material Bank"},{"location":"CaseStudies/2019/ABACUS/#aalto-university","text":"Antti Rasila, Guangdong Technion - Israel Institute of Technology","title":"Aalto University"},{"location":"CaseStudies/2019/ABACUS/#abstract","text":"Since 2006, Aalto University has been using STACK to run online assessments within their Engineering Mathematics courses. Initially, the University was running a STACK version developed in-house specifically for the University, but this was later merged back into the main STACK branch in version 3.0. After receiving funding, the material bank Abacus was created, with the purpose of helping institutions collaborate and share STACK questions. The project's agreement was written in a way that ensured question authors kept their copyright, while still encouraging collaboration. Abacus has 30 members and its courses cover most of undergraduate mathematics and many parts of physics.","title":"Abstract"},{"location":"CaseStudies/2019/ABACUS/#motivation","text":"The MatTa group (\"Matematiikkaa tietokoneavusteisesti\"; \"mathematics by using computers\") was founded in 1990s by lecturer Emeritus Simo K. Kivel\u00e4 at the Department of Mathematics and Systems Analysis at Aalto University, formerly known as Helsinki University of Technology. The purpose of the group was to investigate the use of computers and information technology to teach engineering mathematics. Initially, the projects involved, for example, using visualisations, multimedia and symbolic computation to make mathematical content more interesting and accessible for students. The group also produced a number of free Finnish language electronic lecture notes with interactive content and a substantial database of traditional pen and paper exercise assignments called Euler. In 2006, the group started to take interest in automatic assessment, as they believed computer-aided methodologies could achieve a practical impact in teaching activities there. There was also hope at the University that Computer Aided Assessment could reduce the number of students assistants required to grade homework, both to save cost and because a sufficient number of qualified graders was not always available. Initially, the group focused on the Maple T.A. system, however it was found lacking in several aspects. The most important of these were performance issues and an incompatibility with various browsers, in particular ones available for the Linux operating system. The high licensing fees were also a problem, as they could undo all the savings that the University hoped to achieve by using the system. In spring of 2006, the group started gaining interest in STACK, which has an open source license. This license would allow the University to use its in-house software development skills to improve the platform where needed, and it would also guarantee that licence fees would not be imposed in the future. After deciding to use STACK, which was running its standalone version 1.x at the time, the group spent the summer of 2006 modifying the software to better suit the University's needs. This included replacing the rendering code of mathematical formulas to support browsers other than Microsoft Internet Explorer, translating the software to Finnish and a Shibboleth based integration with the Finnish national Haka single-sign-in system.","title":"Motivation"},{"location":"CaseStudies/2019/ABACUS/#implementing-stack","text":"Figure: An interactive STACK question from Aalto University's \"Multivariable Calculus\" course, where students drag points along a contour line. After modifying the system, the University started testing STACK. The initial test was with the university's Basic Course in Engineering Mathematics KP3. A. Rasila wrote four STACK assignments for each week of the course, all of which were relatively simple questions involving numerical or algebraic input. The system had numerous small technical issues, but the students were generally happy with the system as evidenced both by student feedback and general usage statistics [1]. Encouraged by the positive results, it was decided to test the system more comprehensively to convince the teaching community that automatic assessment was worth of the effort in teaching engineering mathematics. It was important to show that the online assessment could be used by teachers with little programming skill, and that it would not cause a large increase in their workload. This was crucial for the long-term success of the project, as MatTa's previously developed materials were often only used by a handful of teachers, most of whom where developers themselves. Furthermore, the group needed to demonstrate that the system had real cost savings, as well as good learning outcomes compared to traditional types of assignments. The University set up an experimental course \"Discrete Mathematics\", where STACK would form a significant portion of the final grade [2]. Following the positive results of this course, the use of STACK began to spread at the University, and within three years, most basic courses in Engineering Mathematics at Aalto University were using STACK.","title":"Implementing STACK"},{"location":"CaseStudies/2019/ABACUS/#stack-developments","text":"A key ingredient in the success of STACK at Aalto University were the in-house developments by programmer Matti Harjula, also wrote his Master\u2019s Thesis on this work [3]. His initial work included analysing the data of the first 2006 experiment and further developing the system to address any shortcomings. His project was successful, as it led to a system that many lecturers at the department were willing to use, and no major issues were identified in the subsequent use of the system. However, it also led to a new problem. Independently from Aalto University, the British STACK developers had been developing STACK 2.0, which was very different from the 1.x series Aalto University had been using for their work. The in-house developments by Aalto University were not easily implemented into STACK 2.0, but merging the Aalto University code back into the trunk of STACK was still necessary for a number of reasons. Firstly, a unified code base would speed up the overall development of STACK, and the Department at Aalto University did not intend to permanently commit many resources to maintaining the system. Secondly, there was interest from other Finnish universities to try the system, however they preferred to use the \u201cofficial\u201d British version of STACK, which would prevent them from using the materials developed at Aalto University. Because of this, the Finnish and British developers agreed to join forces in combining their work into STACK 3.0. During the STACK 3.0 merge, experimental features of STACK were also being added to the Aalto University version, as documented in section 7.8 of [4]. These features were related to several pedagogical ideas, detailed in [5,6,7].","title":"STACK Developments"},{"location":"CaseStudies/2019/ABACUS/#creating-abacus","text":"There were two key advancements in 2015. Firstly, STACK 3.0 was completed and Aalto University had finalised their plans to the deploy the system as a replacement to their old in-house version. Since the University was now using the official STACK version, it was easier to collaborate with other Universities on STACK material. Secondly, the consortium of the seven Finnish technology universities called for proposals in developing collaborative practices in education. A draft proposal for joint development of electronic materials for mathematics education was proposed and selected as a pilot project with over half a million euros of funding. A. Rasila was chosen as the national coordinator of this project, which become known as the Abacus consortium [8]. Figure: The Abacus logo. Abacus is a database of teaching materials, mainly STACK questions, covering most basic topics in undergraduate mathematics. Its mission statement is to help lecturers find high quality and free learning materials, achieved through facilitating the sharing of online teaching resources between institutions. National and international collaboration is at the heart of the project, as it helps standardise the platform, minimise the necessary contribution of each institution and contribute to the overall market share of the platform. Language differences between courses is not a concern, since adding translations to individual questions are almost trivial compared to the expense of actually programming the mathematics e-content. In drafting the initial consortium agreement, Abacus drew from two other related projects, namely a 2009 e-learning collaboration project with the Bavarian Virtual University VHB, which was funded by the later discontinued Finnish Virtual University, and the MatTa material bank Euler.","title":"Creating Abacus"},{"location":"CaseStudies/2019/ABACUS/#fair-use","text":"In projects largely developed through public and institutional funding, fair use is a common problem. Some partners may feel they are contributing more than the rest, and hence will not be interested in collaboration and instead push for in-house development. Furthermore, collaborators who develop materials without being paid are often unhappy when someone else makes even minor monetary gains from their work, which has led to a widespread use of non-commercial licenses for academic work. While understandable, these restrictions hinder the acceptance of platforms like Abacus, and lead to divisions in the community. Furthermore, non-commercial licenses can be confusing, as the exact nature of commercial activity is not clearly defined in academia. For example, is \"free\" work done by a salaried lecturer commercial use? Finally, it can be necessary for institutions to share the sources of assignments due to international differences in notation, course content and language. On the other hand, a pure open source model is not particularly attractive for e-assessment materials, since students should not be able to search online for the teachers' answers. To solve these problems, the Abacus consortium agreement was written such that there are no strict legal restrictions on what kind of institutions can join the consortium or what kinds of materials can be included. The materials are shared in a way such that each partner gets substantial rights to develop them based on a license similar to open source, but is not allowed to share the source code with third parties. The original developers retain their copyright of the materials and are allowed to give them other licenses besides the one required by Abacus. Since new members are reviewed by the consortium's steering group and are required to make a one-time contribution to the consortium, the agreement encourages collaboration and guarantees that existing partners benefit from the growth of the consortium.","title":"Fair Use"},{"location":"CaseStudies/2019/ABACUS/#outlook","text":"As of July 2019, the Abacus consortium consists of 30 members, 17 of which are from Finland, as well as three from Estonia and two from both Germany and Norway. Other countries present in the consortium are China, France, Ireland, Portugal, Ukraine, and the United Kingdom. There are ongoing discussions with several other potential partners, mainly from Europe. The database currently contains problem assignments for most bachelor level courses in mathematics, as well as a substantial number of physics assignments. Although Abacus accepts contributions in any language, most materials are available in English. Translations of the remaining Finnish-only materials are ongoing, and are expected to be completed in 2020.","title":"Outlook"},{"location":"CaseStudies/2019/ABACUS/#references","text":"[1] A. Rasila, M. Harjula, and K. Zenger. Automatic assessment of mathematics exercises: Experiences and future prospects. In ReekTori 2007: Symposium of Engineering Education, 70-80. Helsinki University of Technology, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2007. [2] A. Rasila, L. Havola, H. Majander, and J. Malinen. Automatic assessment in engineering mathematics: evaluation of the impact. In ReekTori 2010: Symposium of Engineering Education. Aalto University, Finland, Teaching and Learning Development Unit, http://www.dipoli.tkk.fi/ok, 2010. [3] M. Harjula. Mathematics exercise system with automatic assessment. Master's thesis, Helsinki University of Technology, 2008. [4] C. J. Sangwin. Computer Aided Assessment of Mathematics. Oxford University Press, Oxford, UK, 2013. [5] H. Majander and A. Rasila. Tutkimus suuntaamassa 2010-luvun matemaattisten aineiden opetusta, Experiences of continuous formative assessment in engineering mathematics, 197-214. Tampereen yliopistopaino Oy - Juvenes Print, 2011. [6] A. Rasila, J. Malinen, and H. Tiitu. Automatic assement and conceptual understanding. Teaching Mathematics and its Applications, 34(3):149-159, 2015. [7] T. Pelkola, A. Rasila, and C. J. Sangwin. Investigating Bloom's learning for mastery in mathematics with online assessment. Informatics in Education, 17(2), 363-380, 2018. [8] A. Rasila. E-assessment material bank abacus. In Proceedings of EDILEARN16, 8th Annual International Conference on Education and New Learning Technologies, July 2016. STACK at Scale: The Open University Promoting STACK Across Disciplines at Loughborough University","title":"References"},{"location":"CaseStudies/2019/Adaptive/","text":"Adaptive Self-learning Exercises Ruhr-Universit\u00e4t Bochum Michael Kallweit Abstract At the Ruhr-Universit\u00e4t Bochum, students from all disciplines are offered digital mathematics tasks in an e-learning course for self-study in order to prepare and revise. These questions make intensive use of the randomisation and differentiated feedback options of the STACK question type. Some tasks have been supplemented by adaptive exercises, which guide the students through complex tasks. These adaptive tasks have had great success, are shown to have the same level of student engagement as paper-based tasks and be a better predictor of exam performance. Introduction At the Ruhr University Bochum, digital exercises have been used in courses at the Faculty of Mathematics since 2011, and since 2013 this has included STACK. In 2015, a cross-curricular e-learning course was set up, in which students can repeat and process selected topics for exam preparation by themselves. The course takes advantages of Moodle's gamification features: students gain points for engaging with quizzes, contributing to a \"level\". They also earn badges for completing material in a short time or with a high mark. Additionally, students have access to digital tutorial support. In addition to these features, the University wanted to add learning exercises that adapt to students' needs. Motivation In online assessment, weekly digital exercises are often done in \"examination mode\", that is, where students complete tasks in a given timeframe without interacting with the teachers in the meantime. Normally students are only allowed one attempt at the question, and differentiated feedback is only available for the students after the deadline. However, experience shows that students rarely use the detailed written feedback provided and are satisfied with just seeing their score. This observation is consistent with the students' responses to manually graded paper-based homework. Additionally, often valuable reflective loops that promote learning are omitted. As highlighted by Hattie's meta-analysis [2 and 3], it is important to increase students' interactivity with the feedback on their solutions. According to [4], good feedback should show concrete possibilities of how gaps in skills can be closed by students. Contrast this with tutorial lessons, where teachers often help students find a solution path. In the form of minimal assistance, teachers will intervene to help students achieve steady progress in dealing with a problem. If the students take an erroneous path to a solution, the teacher not just corrects the error, but will instead take the student on the path through the task. After being steered on the right path, the student will often fix the error by themselves. This procedure is known as instructional scaffolding: with just minimal support from the teacher, the students can master the individual tasks themselves, and can actively reflect on difficulties and mistakes during the process to close gaps in their knowledge. The developers at Ruhr-Universit\u00e4t Bochum wanted to bring this concept to online assessment: to build an online assessment system that can carry out instructional scaffolding to help students find a solution path. STACK was ideal for this, as its features in providing specific feedback depending on the properties of students answers provide a great foundation for an adaptive system. Adaptive self-learning approach Instead of being confronted by a teacher in a tutorial group, students can process adaptive digital self-learning tasks. Following the above principles, students follow an adaptive path of intermediate step tasks in small steps after submitting an incorrectly answered task. The intermediate steps focus on concrete knowledge and skills that must be combined to solve the original task. The adaptive methods were tested in entrance exams at secondary level II schools, through diagnostic error analysis tools [5,6,7]. The goal of this was to isolate the underlying errors behind why students incorrectly process digital tasks. Using digital tasks with STACK and a complex composition of digital tasks, the researchers achieved a considerable error detection rate of about 90%. Development of adaptive self-learning tasks Adaptive self-learning tasks follow the scaffolding principle. The error analysis and subsequent presentation of intermediate steps take place within the potential response trees of a STACK question, and offer added value compared to traditional digital tasks: In contrast to tasks in \"examination mode\", students actively deal with difficulties and errors. These are independently overcome by support in small steps and aim at a lasting learning success and increased motivation. Even with randomized STACK tasks, intermediate exercises refer to the task set at the beginning. A reference to the initial problem remains visible along the entire learning path. There are no limits on the design and variety of adaptive paths through the task. With each intermediate step, the next step can be selected on the basis of the student's individual input. The individual paths through the task are included in the source code of the individual STACK task, which allows questions to be easily shared between courses. The STACK Response Analysis Tool gives teachers insight into the paths taken by students. Technical implementation Moodle currently only offers limited possibilities for adaptively designing a sequence of tasks in tests. Hence, the adaptive tasks were introduced at the level of individual STACK questions. For each question, the potential response tree analyses the student's solution, and if they have made an error, shows a link to the starting point of an individual path. By including an externally stored Javascript file, the next intermediate step exercise becomes visible only by clicking on a button. The analysis of the input for this intermediate step is also stored in a response tree which adaptively defines the subsequent tasks. By repeating steps and integrating additional ones, the adaptive procedure can simulate real tutorial support. Example The following elementary example for matrix multiplication illustrates the central principles of the adaptive task format: Figure: An adaptable question about matrix multiplication. If the input of the solution is incorrect, the student is informed that they can work on the task again in guided intermediate steps via the \"Weiter\" (\"Next\") button. Figure: In the feedback, students may be told to work through the problem again, step-by-step. The first intermediate step then opens directly below the actual task, in this case asking students to identify the rule that is used when calculating matrix products. Subsequent steps will be available each time a step is correctly completed and the student clicks \"Next\" Figure: The three intermediate problem-solving steps for this question about matrix multiplication. The entire adaptive path with all intermediate step tasks has the following structure. Figure: An overview of the adaptive path for the matrix multiplication question. It is also possible to ask students to make a decision about which direction they want to take. Branches at which students make decisions about which direction they want to take are also possible. Overall, the feedback can be structured in a variety of ways according to Zech's hierarchy levels, with a focus on motivation, strategy or content help [8]. Results When comparing the University's new online assessment to their old, multiple-choice based system, several improvements become apparent. In multiple choice questions, you can only have a finite number of \"distractors\", but in STACK you can give feedback on an unlimited number of answers. In particular, the developers compared a question about expanding (2x+3y)^2, and found that while the old system had only 9 distractor options, the STACK system had registered 41 different answers over its lifetime, which could be grouped into 28 different types of mistakes. This is a major improvement on the number of mistakes students can receive specific feedback about. Additionally, the developers wanted to compare the performance of paper-based and digital homework. Across all courses, they did not find any significant difference in how many tasks students complete between the two systems. This is encouraging; the University saves resources by not relying on human markers for homework, and this confirms that they have not lost any functionality or student engagement by moving towards online assessment. For the course \"Mathematics for Chemistry\", the correlation between paper-based homework scores and exam scores was found to be 0.56, but the correlation between online homework scores and exam scores was 0.63. Similar results were found for the other courses at the University. Hence, online quiz scores are a better predictor for exam scores. Figure: Comparing both paper-based and online homework scores with exam scores, for the course \"Mathematics for Chemistry\". Challenges One of the main challenges of STACK integration was keeping up with new versions. It was important to convince administrators that going through the trouble of updating STACK was worth it, as new updates and features could be important to question authors. Additionally, there was a challenge in distributing the questions to new users, since Moodle's options for managing and distributing questions were found lacking. To solve this, a database for managing STACK questions in moodleXML files was created, which included more sophisticated search options. For each question, the system generates an overview pdf file with a short description, information on available languages, screenshots and an automatically generated overview of the potential response trees. About 700 questions are in the database, and because of its usability, it is easy to convince new users that it is simple to find good STACK questions. Enablers It was helpful to have a strong community of STACK users to help with projects. For example, one of the lecturers held a seminar to teach effective STACK usage to students training to become school teachers. The students of this class became a valuable community of STACK users willing to help with other projects. Additionally, it was valuable that STACK had been translated to German, as this allowed the University to easily spread STACK to other German institutions and build good partners. What's Next? The STACK courses at Ruhr-Universit\u00e4t Bochum continue to be improved on. Future additions may include using more sophisticated features in questions, such as equivalence reasoning inputs and interactive JSXGraph visuals. References [1] M. Kallweit and E. Glasmachers. Adaptive selbstlernaufgaben mit STACK. 2019. [2] J. Hattie. Visible learning: A synthesis of over 800 meta analyses relating to achievement. Routledge, 2009. [3] J. Hattie and H. Timperley. The power of feedback. Review of Educational Research , 77(1):91-112, 2007. [4] D.J. Nicol and D. Macfarlane-Dick. Formative assessment and self-regulated learning: a model and seven principles of good feedback practice. Studies in Higher Education, 31(2):199-218, 2006. [5] R. Bruder, N. Feldt Caesar, A. Pallack, G. Pinkernell, and A. Wynands. Mathematisches grundwissen und grundk\u007fonnen in der sekundarstufe ii. W. Blum et al. (Hrsg.) , Bildungsstandards aktuell: Mathematik in der Sekundarstufe II, pages 108-124, 2015. [6] M. Schaub. Einsatz des elementarisierenden testens im ein- und ausgangstest des online vorkurses vemint. Beitr\u00e4ge zum Mathematikunterricht 2018., pages 1567-1570, 2018. [7] F. Zech. Grundkurs Mathematikdidaktik. Theoretische und praktische Anleitungen f\u00fcr das Lehren und Lernen von Mathematik. 1978. STACK for a Physics Textbook A Flick Interface for Maths Input","title":"Adaptive Self-learning Exercises"},{"location":"CaseStudies/2019/Adaptive/#adaptive-self-learning-exercises","text":"","title":"Adaptive Self-learning Exercises"},{"location":"CaseStudies/2019/Adaptive/#ruhr-universitat-bochum","text":"Michael Kallweit","title":"Ruhr-Universit\u00e4t Bochum"},{"location":"CaseStudies/2019/Adaptive/#abstract","text":"At the Ruhr-Universit\u00e4t Bochum, students from all disciplines are offered digital mathematics tasks in an e-learning course for self-study in order to prepare and revise. These questions make intensive use of the randomisation and differentiated feedback options of the STACK question type. Some tasks have been supplemented by adaptive exercises, which guide the students through complex tasks. These adaptive tasks have had great success, are shown to have the same level of student engagement as paper-based tasks and be a better predictor of exam performance.","title":"Abstract"},{"location":"CaseStudies/2019/Adaptive/#introduction","text":"At the Ruhr University Bochum, digital exercises have been used in courses at the Faculty of Mathematics since 2011, and since 2013 this has included STACK. In 2015, a cross-curricular e-learning course was set up, in which students can repeat and process selected topics for exam preparation by themselves. The course takes advantages of Moodle's gamification features: students gain points for engaging with quizzes, contributing to a \"level\". They also earn badges for completing material in a short time or with a high mark. Additionally, students have access to digital tutorial support. In addition to these features, the University wanted to add learning exercises that adapt to students' needs.","title":"Introduction"},{"location":"CaseStudies/2019/Adaptive/#motivation","text":"In online assessment, weekly digital exercises are often done in \"examination mode\", that is, where students complete tasks in a given timeframe without interacting with the teachers in the meantime. Normally students are only allowed one attempt at the question, and differentiated feedback is only available for the students after the deadline. However, experience shows that students rarely use the detailed written feedback provided and are satisfied with just seeing their score. This observation is consistent with the students' responses to manually graded paper-based homework. Additionally, often valuable reflective loops that promote learning are omitted. As highlighted by Hattie's meta-analysis [2 and 3], it is important to increase students' interactivity with the feedback on their solutions. According to [4], good feedback should show concrete possibilities of how gaps in skills can be closed by students. Contrast this with tutorial lessons, where teachers often help students find a solution path. In the form of minimal assistance, teachers will intervene to help students achieve steady progress in dealing with a problem. If the students take an erroneous path to a solution, the teacher not just corrects the error, but will instead take the student on the path through the task. After being steered on the right path, the student will often fix the error by themselves. This procedure is known as instructional scaffolding: with just minimal support from the teacher, the students can master the individual tasks themselves, and can actively reflect on difficulties and mistakes during the process to close gaps in their knowledge. The developers at Ruhr-Universit\u00e4t Bochum wanted to bring this concept to online assessment: to build an online assessment system that can carry out instructional scaffolding to help students find a solution path. STACK was ideal for this, as its features in providing specific feedback depending on the properties of students answers provide a great foundation for an adaptive system.","title":"Motivation"},{"location":"CaseStudies/2019/Adaptive/#adaptive-self-learning-approach","text":"Instead of being confronted by a teacher in a tutorial group, students can process adaptive digital self-learning tasks. Following the above principles, students follow an adaptive path of intermediate step tasks in small steps after submitting an incorrectly answered task. The intermediate steps focus on concrete knowledge and skills that must be combined to solve the original task. The adaptive methods were tested in entrance exams at secondary level II schools, through diagnostic error analysis tools [5,6,7]. The goal of this was to isolate the underlying errors behind why students incorrectly process digital tasks. Using digital tasks with STACK and a complex composition of digital tasks, the researchers achieved a considerable error detection rate of about 90%.","title":"Adaptive self-learning approach"},{"location":"CaseStudies/2019/Adaptive/#development-of-adaptive-self-learning-tasks","text":"Adaptive self-learning tasks follow the scaffolding principle. The error analysis and subsequent presentation of intermediate steps take place within the potential response trees of a STACK question, and offer added value compared to traditional digital tasks: In contrast to tasks in \"examination mode\", students actively deal with difficulties and errors. These are independently overcome by support in small steps and aim at a lasting learning success and increased motivation. Even with randomized STACK tasks, intermediate exercises refer to the task set at the beginning. A reference to the initial problem remains visible along the entire learning path. There are no limits on the design and variety of adaptive paths through the task. With each intermediate step, the next step can be selected on the basis of the student's individual input. The individual paths through the task are included in the source code of the individual STACK task, which allows questions to be easily shared between courses. The STACK Response Analysis Tool gives teachers insight into the paths taken by students.","title":"Development of adaptive self-learning tasks"},{"location":"CaseStudies/2019/Adaptive/#technical-implementation","text":"Moodle currently only offers limited possibilities for adaptively designing a sequence of tasks in tests. Hence, the adaptive tasks were introduced at the level of individual STACK questions. For each question, the potential response tree analyses the student's solution, and if they have made an error, shows a link to the starting point of an individual path. By including an externally stored Javascript file, the next intermediate step exercise becomes visible only by clicking on a button. The analysis of the input for this intermediate step is also stored in a response tree which adaptively defines the subsequent tasks. By repeating steps and integrating additional ones, the adaptive procedure can simulate real tutorial support.","title":"Technical implementation"},{"location":"CaseStudies/2019/Adaptive/#example","text":"The following elementary example for matrix multiplication illustrates the central principles of the adaptive task format: Figure: An adaptable question about matrix multiplication. If the input of the solution is incorrect, the student is informed that they can work on the task again in guided intermediate steps via the \"Weiter\" (\"Next\") button. Figure: In the feedback, students may be told to work through the problem again, step-by-step. The first intermediate step then opens directly below the actual task, in this case asking students to identify the rule that is used when calculating matrix products. Subsequent steps will be available each time a step is correctly completed and the student clicks \"Next\" Figure: The three intermediate problem-solving steps for this question about matrix multiplication. The entire adaptive path with all intermediate step tasks has the following structure. Figure: An overview of the adaptive path for the matrix multiplication question. It is also possible to ask students to make a decision about which direction they want to take. Branches at which students make decisions about which direction they want to take are also possible. Overall, the feedback can be structured in a variety of ways according to Zech's hierarchy levels, with a focus on motivation, strategy or content help [8].","title":"Example"},{"location":"CaseStudies/2019/Adaptive/#results","text":"When comparing the University's new online assessment to their old, multiple-choice based system, several improvements become apparent. In multiple choice questions, you can only have a finite number of \"distractors\", but in STACK you can give feedback on an unlimited number of answers. In particular, the developers compared a question about expanding (2x+3y)^2, and found that while the old system had only 9 distractor options, the STACK system had registered 41 different answers over its lifetime, which could be grouped into 28 different types of mistakes. This is a major improvement on the number of mistakes students can receive specific feedback about. Additionally, the developers wanted to compare the performance of paper-based and digital homework. Across all courses, they did not find any significant difference in how many tasks students complete between the two systems. This is encouraging; the University saves resources by not relying on human markers for homework, and this confirms that they have not lost any functionality or student engagement by moving towards online assessment. For the course \"Mathematics for Chemistry\", the correlation between paper-based homework scores and exam scores was found to be 0.56, but the correlation between online homework scores and exam scores was 0.63. Similar results were found for the other courses at the University. Hence, online quiz scores are a better predictor for exam scores. Figure: Comparing both paper-based and online homework scores with exam scores, for the course \"Mathematics for Chemistry\".","title":"Results"},{"location":"CaseStudies/2019/Adaptive/#challenges","text":"One of the main challenges of STACK integration was keeping up with new versions. It was important to convince administrators that going through the trouble of updating STACK was worth it, as new updates and features could be important to question authors. Additionally, there was a challenge in distributing the questions to new users, since Moodle's options for managing and distributing questions were found lacking. To solve this, a database for managing STACK questions in moodleXML files was created, which included more sophisticated search options. For each question, the system generates an overview pdf file with a short description, information on available languages, screenshots and an automatically generated overview of the potential response trees. About 700 questions are in the database, and because of its usability, it is easy to convince new users that it is simple to find good STACK questions.","title":"Challenges"},{"location":"CaseStudies/2019/Adaptive/#enablers","text":"It was helpful to have a strong community of STACK users to help with projects. For example, one of the lecturers held a seminar to teach effective STACK usage to students training to become school teachers. The students of this class became a valuable community of STACK users willing to help with other projects. Additionally, it was valuable that STACK had been translated to German, as this allowed the University to easily spread STACK to other German institutions and build good partners.","title":"Enablers"},{"location":"CaseStudies/2019/Adaptive/#whats-next","text":"The STACK courses at Ruhr-Universit\u00e4t Bochum continue to be improved on. Future additions may include using more sophisticated features in questions, such as equivalence reasoning inputs and interactive JSXGraph visuals.","title":"What's Next?"},{"location":"CaseStudies/2019/Adaptive/#references","text":"[1] M. Kallweit and E. Glasmachers. Adaptive selbstlernaufgaben mit STACK. 2019. [2] J. Hattie. Visible learning: A synthesis of over 800 meta analyses relating to achievement. Routledge, 2009. [3] J. Hattie and H. Timperley. The power of feedback. Review of Educational Research , 77(1):91-112, 2007. [4] D.J. Nicol and D. Macfarlane-Dick. Formative assessment and self-regulated learning: a model and seven principles of good feedback practice. Studies in Higher Education, 31(2):199-218, 2006. [5] R. Bruder, N. Feldt Caesar, A. Pallack, G. Pinkernell, and A. Wynands. Mathematisches grundwissen und grundk\u007fonnen in der sekundarstufe ii. W. Blum et al. (Hrsg.) , Bildungsstandards aktuell: Mathematik in der Sekundarstufe II, pages 108-124, 2015. [6] M. Schaub. Einsatz des elementarisierenden testens im ein- und ausgangstest des online vorkurses vemint. Beitr\u00e4ge zum Mathematikunterricht 2018., pages 1567-1570, 2018. [7] F. Zech. Grundkurs Mathematikdidaktik. Theoretische und praktische Anleitungen f\u00fcr das Lehren und Lernen von Mathematik. 1978. STACK for a Physics Textbook A Flick Interface for Maths Input","title":"References"},{"location":"CaseStudies/2019/Edinburgh/","text":"Institutional Support for STACK in Edinburgh University of Edinburgh Interview with Chris Sangwin Abstract At the University of Edinburgh, online assessment has been consolidated with in-house support, mostly with STACK, for the majority of year one and two mathematics modules and for many other mathematics and general science courses. A dedicated learning-technologist post was created to help course organisers implement online assessment. Replacing the current online assessment with human marking is currently estimated to save the School over 6100 hours of work marking students' work each year. Motivation The School of Mathematics at the University of Edinburgh had, over the years, grown to use a number of separate online assessment systems. However, there was growing concern that using separate systems created a number of problems, for example students had to learn the syntax of many different systems. It was also problematic that students needed to purchase access to the online systems provided by publishers. At the same time, student numbers in the UK continued to grow [1], and there were growing expectations from students for more frequent formative assessment in their courses. This motivated the school to bring all assessments in-house with STACK. Execution Figure: A typical Introduction to Linear Algebra question. STACK was first used in Edinburgh at a small scale for the Lothian Equal Access Programme for Schools (LEAPS) summer school in 2016. Following the success with LEAPS, STACK was used in larger courses such as Introduction to Linear Algebra, a year one module with over 600 students, in the 2016-17 academic year. The University's primary learning environment is Blackboard \"LEARN\", so students gain access to a dedicated STACK service via the LTI protocol through their normal LEARN pages. Having identified the need for additional support, the School of Mathematics created a dedicated \"Learning Technologist\" post. The primary goal of this post was to transform existing (largely paper-based) problem sets into online assessments and to develop alternatives to existing external online assessments. The Technologist used the following process to transform these assessments. Before the year started, current forms of assessment were reviewed, and suitable STACK questions were written together with course organisers. During the academic year, quizzes were made available, and their usage monitored. When the year was over, this monitoring data was analysed and questions were updated where appropriate. Creating online assessments is significant additional work, but once the quizzes have been created they require minimal work to maintain and can last for the lifetime of the course. Because of this cost-benefit relationship, employing a Learning Technologist has been an effective strategy in ensuring change actually took place. Results In 2019, many courses have online assessments using STACK. A course will typically have weekly or fortnightly assessment, many using a combination of flipped classroom \"reading quizzes\" (RQ), formative \"practice quizzes\" (PQ) and summative \"assessed quizzes\" (AQ). Some courses also make an optional mock online exam available to students. The following table provides an overview from the 18/19 year, including the number of students, how often quizzes were given out (per week W or semester S), the average number of questions per quiz (#Q/quiz) and the total number of questions (#Qs). Year Course Students Quizzes #Q/quiz #Qs 1 Introduction to Linear Algebra 604 2 RQ/W 2-3 1 AQ/W 6-8 110 1 Calculus and its Applications 594 1 RQ/W 4 1 AQ/W 10 150 1 Proofs and Problem Solving 344 1 RQ/W 2 20 1 Engineering Mathematics 1a 393 3 PQ/W 5 Mathematics for Natural Sciences 1a 138 1 AQ/W 7-10 240 1 Engineering Mathematics 1b 401 3 PQ/W 3-5 Mathematics for Natural Sciences 1b 136 1 AQ/W 7-10 200 1 Mathematics for Physics 1 193 5 AQ/S 5 25 1 Mathematics for Physics 2 202 5 AQ/S 6 30 1 Fundamentals of Algebra and Calculus 113 5 PQ/W 10-20 3 AQ/W 6-12 950 2 Probability 312 1 AQ/W 3-5 36 2 Several Variable Calculus and DEs 287 1 PQ/W 5-12 1 AQ/W 5-10 180 3 Honours Algebra 202 9 AQ/S 1-8 46 3 Combinatorics and Graph Theory 60 2 RQ/W 2 4 AQ/S 1-6 45 3 Symmetry and Geometry 36 1 AQ/W 4-7 45 4 Galois Theory 27 1 RQ/W 2 22 PG Fundamentals of Optimization 190 3 AQ/S 4-8 16 PG Introduction to Probability and Statistics 23 1 PQ/W 6-8 5 AQ/S 4 62 Table: Courses using STACK assessments at The University of Edinburgh 2018-19. Cost Over the course of this project, the Learning Technologist estimates that developing a fully functioning quiz of 8 questions took about two person-days, or 16 hours of work, to create. As an example, consider the large first-year course \"Introduction to Linear Algebra\", with around 600 students in 65 tutorial groups. Replacing half of the weekly hand-ins with online assessments has saved each tutor over one hour of marking per week. Hence, over 65 hours of work is saved each week as a result. In addition, the students now complete more than double the number of practice problems, providing them with enhanced formative feedback which would be impossible to resource otherwise. Since online quizzes can be reused each year, this will be a consistent saving for as long as the course remains. Overall, it is estimated that STACK saves the University over 6100 hours of work each year [2]. Figure: Many School of Mathematics courses are taken at the James Clerk Maxwell Building. Barriers The goal was to have the first 4-6 weeks of quizzes ready before the beginning of a semester. However, as the term progressed, it was not unusual for the last few quizzes to be ready only \"at the last moment\". This did not give the question authors a lot of time to review their questions, but does reflect the realities of teaching. It was also important that the course organiser were fully involved in the authoring process. They had to give clear and explicit guidance on the learning objectives and help review the mathematical content. Finally, when working with large question banks, organising became difficult. Large Moodle question banks are tricky to browse, and maintenance becomes tedious when questions are duplicated between similar courses. Enablers The most significant factor in the success of this project was the dedicated Learning Technologist post. This was essential, as it assured course organisers had practical support, and that online quizzes could have a consistently high level of quality. It was helpful to be able to work closely with STACK developers when designing quizzes, in a way that is difficult with non-open-source programs. For example, the \"numerical\" input type which helps students enter answers at a pre-specified level of numerical accuracy, was designed to help cope with the difficulties of assessing vague student answers in statistics questions [3]. What's Next? The School of Mathematics continues to expand the use STACK at the University of Edinburgh. Future challenges involve modifying STACK to suit more conceptual courses, such as group theory and real analysis, as well as expanding into statistics and computer programming using the CodeRunner system [4]. There are also plans for wider use of STACK in summative assessments, with the possibility of using it in online examinations. References [1] Patterns and trends in UK higher education 2018. Universities UK, September 2018. ISBN: 978-1-84036-409-5. [2] C. J. Sangwin and K. Zerva. Developing online learning materials to support undergraduate education at the University of Edinburgh. Mathematics Today, 2019. [3] K. Zerva. Developing STACK assessments in Edinburgh , 2017-2019. In Contributions to the 1st International STACK conference 2018 in F\u007furth, Germany. Zenodo, 2019. [4] R. Lobb and J. Harlow. Coderunner: a tool for assessing computer programming skills. ACM Inroads, 7(1):47{51, March 2016. Promoting STACK Across Disciplines at Loughborough University","title":"Institutional Support for STACK in Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#institutional-support-for-stack-in-edinburgh","text":"","title":"Institutional Support for STACK in Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#university-of-edinburgh","text":"Interview with Chris Sangwin","title":"University of Edinburgh"},{"location":"CaseStudies/2019/Edinburgh/#abstract","text":"At the University of Edinburgh, online assessment has been consolidated with in-house support, mostly with STACK, for the majority of year one and two mathematics modules and for many other mathematics and general science courses. A dedicated learning-technologist post was created to help course organisers implement online assessment. Replacing the current online assessment with human marking is currently estimated to save the School over 6100 hours of work marking students' work each year.","title":"Abstract"},{"location":"CaseStudies/2019/Edinburgh/#motivation","text":"The School of Mathematics at the University of Edinburgh had, over the years, grown to use a number of separate online assessment systems. However, there was growing concern that using separate systems created a number of problems, for example students had to learn the syntax of many different systems. It was also problematic that students needed to purchase access to the online systems provided by publishers. At the same time, student numbers in the UK continued to grow [1], and there were growing expectations from students for more frequent formative assessment in their courses. This motivated the school to bring all assessments in-house with STACK.","title":"Motivation"},{"location":"CaseStudies/2019/Edinburgh/#execution","text":"Figure: A typical Introduction to Linear Algebra question. STACK was first used in Edinburgh at a small scale for the Lothian Equal Access Programme for Schools (LEAPS) summer school in 2016. Following the success with LEAPS, STACK was used in larger courses such as Introduction to Linear Algebra, a year one module with over 600 students, in the 2016-17 academic year. The University's primary learning environment is Blackboard \"LEARN\", so students gain access to a dedicated STACK service via the LTI protocol through their normal LEARN pages. Having identified the need for additional support, the School of Mathematics created a dedicated \"Learning Technologist\" post. The primary goal of this post was to transform existing (largely paper-based) problem sets into online assessments and to develop alternatives to existing external online assessments. The Technologist used the following process to transform these assessments. Before the year started, current forms of assessment were reviewed, and suitable STACK questions were written together with course organisers. During the academic year, quizzes were made available, and their usage monitored. When the year was over, this monitoring data was analysed and questions were updated where appropriate. Creating online assessments is significant additional work, but once the quizzes have been created they require minimal work to maintain and can last for the lifetime of the course. Because of this cost-benefit relationship, employing a Learning Technologist has been an effective strategy in ensuring change actually took place.","title":"Execution"},{"location":"CaseStudies/2019/Edinburgh/#results","text":"In 2019, many courses have online assessments using STACK. A course will typically have weekly or fortnightly assessment, many using a combination of flipped classroom \"reading quizzes\" (RQ), formative \"practice quizzes\" (PQ) and summative \"assessed quizzes\" (AQ). Some courses also make an optional mock online exam available to students. The following table provides an overview from the 18/19 year, including the number of students, how often quizzes were given out (per week W or semester S), the average number of questions per quiz (#Q/quiz) and the total number of questions (#Qs). Year Course Students Quizzes #Q/quiz #Qs 1 Introduction to Linear Algebra 604 2 RQ/W 2-3 1 AQ/W 6-8 110 1 Calculus and its Applications 594 1 RQ/W 4 1 AQ/W 10 150 1 Proofs and Problem Solving 344 1 RQ/W 2 20 1 Engineering Mathematics 1a 393 3 PQ/W 5 Mathematics for Natural Sciences 1a 138 1 AQ/W 7-10 240 1 Engineering Mathematics 1b 401 3 PQ/W 3-5 Mathematics for Natural Sciences 1b 136 1 AQ/W 7-10 200 1 Mathematics for Physics 1 193 5 AQ/S 5 25 1 Mathematics for Physics 2 202 5 AQ/S 6 30 1 Fundamentals of Algebra and Calculus 113 5 PQ/W 10-20 3 AQ/W 6-12 950 2 Probability 312 1 AQ/W 3-5 36 2 Several Variable Calculus and DEs 287 1 PQ/W 5-12 1 AQ/W 5-10 180 3 Honours Algebra 202 9 AQ/S 1-8 46 3 Combinatorics and Graph Theory 60 2 RQ/W 2 4 AQ/S 1-6 45 3 Symmetry and Geometry 36 1 AQ/W 4-7 45 4 Galois Theory 27 1 RQ/W 2 22 PG Fundamentals of Optimization 190 3 AQ/S 4-8 16 PG Introduction to Probability and Statistics 23 1 PQ/W 6-8 5 AQ/S 4 62 Table: Courses using STACK assessments at The University of Edinburgh 2018-19.","title":"Results"},{"location":"CaseStudies/2019/Edinburgh/#cost","text":"Over the course of this project, the Learning Technologist estimates that developing a fully functioning quiz of 8 questions took about two person-days, or 16 hours of work, to create. As an example, consider the large first-year course \"Introduction to Linear Algebra\", with around 600 students in 65 tutorial groups. Replacing half of the weekly hand-ins with online assessments has saved each tutor over one hour of marking per week. Hence, over 65 hours of work is saved each week as a result. In addition, the students now complete more than double the number of practice problems, providing them with enhanced formative feedback which would be impossible to resource otherwise. Since online quizzes can be reused each year, this will be a consistent saving for as long as the course remains. Overall, it is estimated that STACK saves the University over 6100 hours of work each year [2]. Figure: Many School of Mathematics courses are taken at the James Clerk Maxwell Building.","title":"Cost"},{"location":"CaseStudies/2019/Edinburgh/#barriers","text":"The goal was to have the first 4-6 weeks of quizzes ready before the beginning of a semester. However, as the term progressed, it was not unusual for the last few quizzes to be ready only \"at the last moment\". This did not give the question authors a lot of time to review their questions, but does reflect the realities of teaching. It was also important that the course organiser were fully involved in the authoring process. They had to give clear and explicit guidance on the learning objectives and help review the mathematical content. Finally, when working with large question banks, organising became difficult. Large Moodle question banks are tricky to browse, and maintenance becomes tedious when questions are duplicated between similar courses.","title":"Barriers"},{"location":"CaseStudies/2019/Edinburgh/#enablers","text":"The most significant factor in the success of this project was the dedicated Learning Technologist post. This was essential, as it assured course organisers had practical support, and that online quizzes could have a consistently high level of quality. It was helpful to be able to work closely with STACK developers when designing quizzes, in a way that is difficult with non-open-source programs. For example, the \"numerical\" input type which helps students enter answers at a pre-specified level of numerical accuracy, was designed to help cope with the difficulties of assessing vague student answers in statistics questions [3].","title":"Enablers"},{"location":"CaseStudies/2019/Edinburgh/#whats-next","text":"The School of Mathematics continues to expand the use STACK at the University of Edinburgh. Future challenges involve modifying STACK to suit more conceptual courses, such as group theory and real analysis, as well as expanding into statistics and computer programming using the CodeRunner system [4]. There are also plans for wider use of STACK in summative assessments, with the possibility of using it in online examinations.","title":"What's Next?"},{"location":"CaseStudies/2019/Edinburgh/#references","text":"[1] Patterns and trends in UK higher education 2018. Universities UK, September 2018. ISBN: 978-1-84036-409-5. [2] C. J. Sangwin and K. Zerva. Developing online learning materials to support undergraduate education at the University of Edinburgh. Mathematics Today, 2019. [3] K. Zerva. Developing STACK assessments in Edinburgh , 2017-2019. In Contributions to the 1st International STACK conference 2018 in F\u007furth, Germany. Zenodo, 2019. [4] R. Lobb and J. Harlow. Coderunner: a tool for assessing computer programming skills. ACM Inroads, 7(1):47{51, March 2016. Promoting STACK Across Disciplines at Loughborough University","title":"References"},{"location":"CaseStudies/2019/FAC/","text":"Developing a Fully Online Course The University of Edinburgh, UK Interview with George Kinnear and Richard Gratwick Abstract STACK is used in the completely online course \"Fundamentals of Algebra and Calculus\". The course is designed to prepare students for Higher Education (HE) study at the University of Edinburgh, where incoming students have a wide range of mathematical backgrounds. The main barriers were the risk of students using online answer engines to answer questions, and the lack of community. The organizers attempted to address this by clever question design and creating \"autonomous learning groups\". The course was enabled by University support, both in the form of a dedicated learning-technologist post and assistance from colleagues. Subsequent diagnostics test results indicate this course was successful. Introduction Approximately six hundred students typically study first-year mathematics courses at the University of Edinburgh. They have a wide range of mathematical backgrounds and attainments. \"Fundamentals of Algebra and Calculus\" (FAC) was introduced as an additional course, approximately covering SQA Advanced Higher Mathematics and A-Level Further Mathematics, to address the needs of this diverse group. Since some incoming students do not have the chance to take these higher qualifications before coming to university, the course fulfils a role as part of the University\u2019s Widening Participation strategy, enabling access to mathematics courses for a wider range of students, e.g. students admitted through contextual admissions. This also was an attempt to address a concern from the University that one reason for undergraduate non-continuation was a lack of preparation for the mathematical components of students\u2019 degree programmes, particularly those students on non-mathematics degrees within the College of Science and Engineering. Increasingly, the second-semester year 1 \"Calculus and its Applications\" course had been adapted to address these problems. However, staff and students felt that it recently contained too much material. FAC aimed to relieve some of the pressure on this course. FAC was delivered as a completely online course to make it scalable, since the above issues are not unique to the School or the University. FAC plays a role in addressing the so-called \u201cmathematics gap\u201d of attainment, preparing students from a wide range of mathematical backgrounds for HE study, and as such could easily see demand both across the University and beyond. Why Use STACK? FAC is essentially a course in mathematical techniques, assessing routine computation. STACK precisely lets teachers assess such questions automatically and give tailored feedback to students. Quite sophisticated questions can be implemented, for example \u201cgive an example\u201d type questions, asking students to provide examples of e.g. a quadratic with given roots, or a sequence with certain monotonicity or boundedness properties. These are important for \"retrieval practice\", that is, encouraging students to recall previous topics. Execution The course is worth 10 ECTS credits, and consists of approximately 200 hours of work for the student. The course is delivered in ten weekly units, each comprising a number of quizzes intended for students to work through during that week. Each week ends with a 90-minute \"Practice Quiz\" the student can take an unlimited number of times, and a 90-minute \"Final Test\" only allowing one attempt. The test is either given a grade of fail (0-80%), mastery (80-95%) or distinction (95%-100%). The high pass mark encourages students to master a topic before moving on. The final grade is determined by combining the results of the 10 \"Final Tests\" (worth 80%) with a final 2-hour test covering the whole course (worth 20%). The development involved a substantial up-front time investment: writing the material in these quizzes, including over 900 STACK questions. Although some existing questions were borrowed from other courses, the majority of these questions were authored from scratch. The quizzes interleave textbook-style exposition with videos of worked examples, interactive applets and practice questions, and as a result, the questions have a polished and varied look. Two lecturers were involved, each responsible for five units, with final cross-checking and occasional extra contributions. Research Figure: A FAC question aimed at both retrieval practice and building a strong example space. The design of the course was heavily influenced by educational research. Firstly, the course uses \"faded worked examples\", that is, presenting a sequence of problems with different amounts of the solution already worked out. For example, a topic might begin with a full worked solution of a problem, followed by a worked solution with the final step as a STACK input, followed by a worked solution with the last two steps as STACK input, and so on. There is evidence that this is helpful for students [2]. Additionally, given the literature on the importance of \"retrieval practice\" [3], FAC gives plenty of chances for students to recall what they have learned, for example by having quizzes draw on skills from previous weeks. Weeks alternate between algebra and calculus, spacing out practice of the two topics. Furthermore, the lecturers decided not to make feedback for the final tests available to students until after the deadline, since there is evidence suggesting delaying feedback is helpful for learning [5]. Finally, FAC gives students a chance to create strong \"example spaces\" [4], that is, sets of examples that a student can recall for a given topic. Example spaces are developed through \"give-an-example\" style questions, which are easy to write in STACK. Visuals FAC uses a lot of graphs and interactive applets to make questions visually appealing. Visual intuition is an important part of learning about functions, so it is appropriate for graphical components to play a significant part in this course. FAC uses both JSX graphs (which can be coded directly in STACK) and external plugins, like GeoGebra. The advantage of JSX graphs is that they are self-contained; there is no need to worry about changes to external programs, or licensing rights. There is, however, a large cost-benefit analysis to consider. JSX graphs are time-consuming and have a steep learning curve, while external applets are often quick to set up and have simple drag-and-drop features. Figure: FAC uses graphs and other visuals to aid learning. Results The six hundred students taking the first-semester year 1 \"Introduction to Linear Algebra\" course sat a diagnostic test (also delivered through STACK) in September 2018. In January 2019, the students sat the test again with the same questions but different random variants. In the September test, students also enrolled on FAC scored on average fifteen percentage points lower than their peers. This is not surprising; FAC will have been recommended to students who felt like they needed more practice in mathematics fundamentals. However, in January after studying FAC, they had gained these fifteen percentage points and were scoring in line with their peers. This is quantitative evidence that FAC has done exactly what was hoped: removed the discrepancy in attainment between the two groups of students. The lecturers also wanted to know if taking FAC had improved student performance in other maths courses such as \"Introduction to Linear Algebra\" (ILA) and \"Calculus and its Applications\" (CAP). Of students scoring similarly in the September diagnostics test, students who took FAC were scoring better than their peers in online quizzes for CAP. They also scored at a similar level to students who did not take FAC in the exams for ILA and CAP. Figure: Diagnostic results in September (pre) and January (post). Challenges While it is true that authoring a simple STACK question is ultimately straightforward, there was nonetheless a technological hurdle to be cleared. One lecturer was entirely new not only to STACK, but to Maxima and any form of online assessment, and therefore was confronted with quite an intimidating prospect. However, they ended up authoring hundreds of questions without trouble, and are now confident in undertaking significantly more demanding questions. This hurdle was easier to overcome given STACK requires no programming expertise. The lecturers were mindful of the possibility that students could be working through assessed quizzes in one browser tab, with a tool like WolframAlpha open in another. While ultimately this does no benefit to the student, and it remains their responsibility to ensure submitted answers are their own work, the potential of this kind of abuse should be minimised. This just required a bit of cunning at the level of question-setting: turning \u201cfind the derivative of this given function at this given point\u201d into \u201cat what point is the value of the derivative of this given function this given number?\u201d The limitations of an online course include the difficulties of forming meaningful staff-student and student-student interaction. The lack of real staff-student interaction made it hard to gauge whether the level and volume of material was suitable \u2013 anecdotal feedback indicates this was misjudged in at least one of the weekly units. Student-student interaction is important to foster a sense of community. This was addressed by setting up \u201cautonomous learning groups\u201d in which the students could study, in person, once a week, without staff input. Furthermore, students could ask questions in the online forum Piazza, and get in-person help in the MathsBase study room if needed. Enablers The University had created a dedicated learning-technologist post to help design the online assessment and write STACK questions. Their work was invaluable for authoring some of the questions, often given only a one-line sketch of the desired question. The capacity in STACK to clone questions and export questions from other courses was also very useful, making it possible to produce multiple related questions, sharing, for example, a grading structure, without duplicating any work. Finally, it was an advantage that there is substantial \u201cin-house\u201d support at the University, since STACK is now used across the entire first-year curriculum and increasingly beyond. Hence, there are a number of members of staff with experience of authoring questions, and the students are familiar with it. What's Next? A lot of data has been collected in FAC's first year. Quiz responses will be analysed to determine if any questions should be modified. There are also plans to have interviews with students on the effectiveness of the course, which will help identify areas that need work. The course organiser will be looking at improving the \"autonomous learning groups\". Since groups were given weekly tasks and asked to upload solutions to a shared Dropbox, the lecturers can see how much students interacted with these groups. Initially, the engagement was very strong, but half-way through the course, a lot of groups seemed to stop meeting. The course organiser will look at ways to improve turnout for these groups. The course continues to be worked on. The lecturers are considering options for more interactive questions, for example using equivalence reasoning to assess line-by-line arguments, or interactive JSX graphs that ask a student to, for example, \"drag a vector so it is perpendicular to another vector\". The success of FAC paves the way for similar methods to be used in different courses. Other schools have shown interest in creating similar online courses, and some students may find it helpful to have an online course teaching even less advanced maths. References [1] George Kinnear. Delivering an online course using STACK. In Proceedings of the STACK Conference, 2018. [2] A. Renkl, R. K. Atkinson, U. H. Maier, and R. Staley. From Example Study to Problem Solving: Smooth Transitions Help Learning. The Journal of Experimental Education, 70(4):293-315, 2002. [3] H. L. Roediger and A. C. Butler. The critical role of retrieval practice in longterm retention. Trends in Cognitive Sciences, 15(1):20-27, 2011. [4] P. Goldenberg and J. Mason. Shedding light on and with example spaces. Educational Studies in Mathematics, 65(2):183-194, 2008. [5] H. G. Mullet, A. C. Butler, B. Verdin, R. Borries, and E. J. Marsh. Delaying feedback promotes transfer of knowledge despite student preferences to receive feedback immediately. Journal of Applied Research in Memory and Cognition, 3(3):222-229, 2014. STACK for a Physics Textbook","title":"Developing a Fully Online Course"},{"location":"CaseStudies/2019/FAC/#developing-a-fully-online-course","text":"","title":"Developing a Fully Online Course"},{"location":"CaseStudies/2019/FAC/#the-university-of-edinburgh-uk","text":"Interview with George Kinnear and Richard Gratwick","title":"The University of Edinburgh, UK"},{"location":"CaseStudies/2019/FAC/#abstract","text":"STACK is used in the completely online course \"Fundamentals of Algebra and Calculus\". The course is designed to prepare students for Higher Education (HE) study at the University of Edinburgh, where incoming students have a wide range of mathematical backgrounds. The main barriers were the risk of students using online answer engines to answer questions, and the lack of community. The organizers attempted to address this by clever question design and creating \"autonomous learning groups\". The course was enabled by University support, both in the form of a dedicated learning-technologist post and assistance from colleagues. Subsequent diagnostics test results indicate this course was successful.","title":"Abstract"},{"location":"CaseStudies/2019/FAC/#introduction","text":"Approximately six hundred students typically study first-year mathematics courses at the University of Edinburgh. They have a wide range of mathematical backgrounds and attainments. \"Fundamentals of Algebra and Calculus\" (FAC) was introduced as an additional course, approximately covering SQA Advanced Higher Mathematics and A-Level Further Mathematics, to address the needs of this diverse group. Since some incoming students do not have the chance to take these higher qualifications before coming to university, the course fulfils a role as part of the University\u2019s Widening Participation strategy, enabling access to mathematics courses for a wider range of students, e.g. students admitted through contextual admissions. This also was an attempt to address a concern from the University that one reason for undergraduate non-continuation was a lack of preparation for the mathematical components of students\u2019 degree programmes, particularly those students on non-mathematics degrees within the College of Science and Engineering. Increasingly, the second-semester year 1 \"Calculus and its Applications\" course had been adapted to address these problems. However, staff and students felt that it recently contained too much material. FAC aimed to relieve some of the pressure on this course. FAC was delivered as a completely online course to make it scalable, since the above issues are not unique to the School or the University. FAC plays a role in addressing the so-called \u201cmathematics gap\u201d of attainment, preparing students from a wide range of mathematical backgrounds for HE study, and as such could easily see demand both across the University and beyond.","title":"Introduction"},{"location":"CaseStudies/2019/FAC/#why-use-stack","text":"FAC is essentially a course in mathematical techniques, assessing routine computation. STACK precisely lets teachers assess such questions automatically and give tailored feedback to students. Quite sophisticated questions can be implemented, for example \u201cgive an example\u201d type questions, asking students to provide examples of e.g. a quadratic with given roots, or a sequence with certain monotonicity or boundedness properties. These are important for \"retrieval practice\", that is, encouraging students to recall previous topics.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/FAC/#execution","text":"The course is worth 10 ECTS credits, and consists of approximately 200 hours of work for the student. The course is delivered in ten weekly units, each comprising a number of quizzes intended for students to work through during that week. Each week ends with a 90-minute \"Practice Quiz\" the student can take an unlimited number of times, and a 90-minute \"Final Test\" only allowing one attempt. The test is either given a grade of fail (0-80%), mastery (80-95%) or distinction (95%-100%). The high pass mark encourages students to master a topic before moving on. The final grade is determined by combining the results of the 10 \"Final Tests\" (worth 80%) with a final 2-hour test covering the whole course (worth 20%). The development involved a substantial up-front time investment: writing the material in these quizzes, including over 900 STACK questions. Although some existing questions were borrowed from other courses, the majority of these questions were authored from scratch. The quizzes interleave textbook-style exposition with videos of worked examples, interactive applets and practice questions, and as a result, the questions have a polished and varied look. Two lecturers were involved, each responsible for five units, with final cross-checking and occasional extra contributions.","title":"Execution"},{"location":"CaseStudies/2019/FAC/#research","text":"Figure: A FAC question aimed at both retrieval practice and building a strong example space. The design of the course was heavily influenced by educational research. Firstly, the course uses \"faded worked examples\", that is, presenting a sequence of problems with different amounts of the solution already worked out. For example, a topic might begin with a full worked solution of a problem, followed by a worked solution with the final step as a STACK input, followed by a worked solution with the last two steps as STACK input, and so on. There is evidence that this is helpful for students [2]. Additionally, given the literature on the importance of \"retrieval practice\" [3], FAC gives plenty of chances for students to recall what they have learned, for example by having quizzes draw on skills from previous weeks. Weeks alternate between algebra and calculus, spacing out practice of the two topics. Furthermore, the lecturers decided not to make feedback for the final tests available to students until after the deadline, since there is evidence suggesting delaying feedback is helpful for learning [5]. Finally, FAC gives students a chance to create strong \"example spaces\" [4], that is, sets of examples that a student can recall for a given topic. Example spaces are developed through \"give-an-example\" style questions, which are easy to write in STACK.","title":"Research"},{"location":"CaseStudies/2019/FAC/#visuals","text":"FAC uses a lot of graphs and interactive applets to make questions visually appealing. Visual intuition is an important part of learning about functions, so it is appropriate for graphical components to play a significant part in this course. FAC uses both JSX graphs (which can be coded directly in STACK) and external plugins, like GeoGebra. The advantage of JSX graphs is that they are self-contained; there is no need to worry about changes to external programs, or licensing rights. There is, however, a large cost-benefit analysis to consider. JSX graphs are time-consuming and have a steep learning curve, while external applets are often quick to set up and have simple drag-and-drop features. Figure: FAC uses graphs and other visuals to aid learning.","title":"Visuals"},{"location":"CaseStudies/2019/FAC/#results","text":"The six hundred students taking the first-semester year 1 \"Introduction to Linear Algebra\" course sat a diagnostic test (also delivered through STACK) in September 2018. In January 2019, the students sat the test again with the same questions but different random variants. In the September test, students also enrolled on FAC scored on average fifteen percentage points lower than their peers. This is not surprising; FAC will have been recommended to students who felt like they needed more practice in mathematics fundamentals. However, in January after studying FAC, they had gained these fifteen percentage points and were scoring in line with their peers. This is quantitative evidence that FAC has done exactly what was hoped: removed the discrepancy in attainment between the two groups of students. The lecturers also wanted to know if taking FAC had improved student performance in other maths courses such as \"Introduction to Linear Algebra\" (ILA) and \"Calculus and its Applications\" (CAP). Of students scoring similarly in the September diagnostics test, students who took FAC were scoring better than their peers in online quizzes for CAP. They also scored at a similar level to students who did not take FAC in the exams for ILA and CAP. Figure: Diagnostic results in September (pre) and January (post).","title":"Results"},{"location":"CaseStudies/2019/FAC/#challenges","text":"While it is true that authoring a simple STACK question is ultimately straightforward, there was nonetheless a technological hurdle to be cleared. One lecturer was entirely new not only to STACK, but to Maxima and any form of online assessment, and therefore was confronted with quite an intimidating prospect. However, they ended up authoring hundreds of questions without trouble, and are now confident in undertaking significantly more demanding questions. This hurdle was easier to overcome given STACK requires no programming expertise. The lecturers were mindful of the possibility that students could be working through assessed quizzes in one browser tab, with a tool like WolframAlpha open in another. While ultimately this does no benefit to the student, and it remains their responsibility to ensure submitted answers are their own work, the potential of this kind of abuse should be minimised. This just required a bit of cunning at the level of question-setting: turning \u201cfind the derivative of this given function at this given point\u201d into \u201cat what point is the value of the derivative of this given function this given number?\u201d The limitations of an online course include the difficulties of forming meaningful staff-student and student-student interaction. The lack of real staff-student interaction made it hard to gauge whether the level and volume of material was suitable \u2013 anecdotal feedback indicates this was misjudged in at least one of the weekly units. Student-student interaction is important to foster a sense of community. This was addressed by setting up \u201cautonomous learning groups\u201d in which the students could study, in person, once a week, without staff input. Furthermore, students could ask questions in the online forum Piazza, and get in-person help in the MathsBase study room if needed.","title":"Challenges"},{"location":"CaseStudies/2019/FAC/#enablers","text":"The University had created a dedicated learning-technologist post to help design the online assessment and write STACK questions. Their work was invaluable for authoring some of the questions, often given only a one-line sketch of the desired question. The capacity in STACK to clone questions and export questions from other courses was also very useful, making it possible to produce multiple related questions, sharing, for example, a grading structure, without duplicating any work. Finally, it was an advantage that there is substantial \u201cin-house\u201d support at the University, since STACK is now used across the entire first-year curriculum and increasingly beyond. Hence, there are a number of members of staff with experience of authoring questions, and the students are familiar with it.","title":"Enablers"},{"location":"CaseStudies/2019/FAC/#whats-next","text":"A lot of data has been collected in FAC's first year. Quiz responses will be analysed to determine if any questions should be modified. There are also plans to have interviews with students on the effectiveness of the course, which will help identify areas that need work. The course organiser will be looking at improving the \"autonomous learning groups\". Since groups were given weekly tasks and asked to upload solutions to a shared Dropbox, the lecturers can see how much students interacted with these groups. Initially, the engagement was very strong, but half-way through the course, a lot of groups seemed to stop meeting. The course organiser will look at ways to improve turnout for these groups. The course continues to be worked on. The lecturers are considering options for more interactive questions, for example using equivalence reasoning to assess line-by-line arguments, or interactive JSX graphs that ask a student to, for example, \"drag a vector so it is perpendicular to another vector\". The success of FAC paves the way for similar methods to be used in different courses. Other schools have shown interest in creating similar online courses, and some students may find it helpful to have an online course teaching even less advanced maths.","title":"What's Next?"},{"location":"CaseStudies/2019/FAC/#references","text":"[1] George Kinnear. Delivering an online course using STACK. In Proceedings of the STACK Conference, 2018. [2] A. Renkl, R. K. Atkinson, U. H. Maier, and R. Staley. From Example Study to Problem Solving: Smooth Transitions Help Learning. The Journal of Experimental Education, 70(4):293-315, 2002. [3] H. L. Roediger and A. C. Butler. The critical role of retrieval practice in longterm retention. Trends in Cognitive Sciences, 15(1):20-27, 2011. [4] P. Goldenberg and J. Mason. Shedding light on and with example spaces. Educational Studies in Mathematics, 65(2):183-194, 2008. [5] H. G. Mullet, A. C. Butler, B. Verdin, R. Borries, and E. J. Marsh. Delaying feedback promotes transfer of knowledge despite student preferences to receive feedback immediately. Journal of Applied Research in Memory and Cognition, 3(3):222-229, 2014. STACK for a Physics Textbook","title":"References"},{"location":"CaseStudies/2019/FlickInterface/","text":"A Flick Interface for Maths Input Graduate School of Informatics, Nagoya University, Japan Yasuyuki Nakamura Sangensha LLC., Japan Takahiro Nakahara Abstract Typing mathematical expressions into mobile devices can be time-consuming. To solve this problem, developers at Nagoya University are developing a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Students can pick a common integer or variable and flick in a direction to quickly turn, for example, x into \\sqrt(x) . A survey of usability suggests students prefer this input type to their traditional keyboard. Motivation As smartphones become increasingly used in schools and universities, it is important to find a reliable way to input mathematical expressions. Inputting mathematics on a computer is not a problem, but on smartphones and other mobile devices it can be much more time-consuming. For example, to type an answer to the question \"Expand (x+2)(x+3)\", students have to enter the expression x^2+5*x+6 into the answer space. On a mobile device, this requires several switches between the alphabetical and numerical views of the keyboard, resulting in 19 key touches for this simple answer. Recently, a flick keyboard for Japanese characters has become very popular in Japan, especially amongst young students. Japanese has three character systems. Hiragana is mostly used for simple and native Japanese words, katakana mostly for foreign words and kanji for all other words. The keyboard shows only a limited number of hiragana[^hiragana] characters, but students can hold and \"flick\" on a key to choose a similar character. Characters are grouped together by sound, for example grouping together na, ni, nu, ne and no. The keyboard will then suggest related kanji and/or katakana characters that share similar sounds. It was the popularity of this keyboard that motivated the developers to create a similar interface for inputting mathematics, as a STACK input type. Execution Figure: The flick interface in action. The flick interface was developed by Yasuyuki Nakamura and Takahiro Nakahara, funded by a grant from the Japan Society for the Promotion of Science. Like the Japanese character keyboard, students are faced with a small set of common inputs. Students can switch between numerical values and common variables by pressing \"123\" and \"xy\", respectively, or see a full keyboard view by clicking the keyboard logo. Pressing on a number reveals some common manipulations, and students can then flick in one direction to turn, for example, \"2\" into \"2x\". The input is compatible with normal keyboards, and will automatically be selected for the type of device being used. The interface is programmed in JavaScript to minimise the dependency on mobile device operating systems. The interface uses MathDox to describe expressions, and the input is then converted to the Maxima format by a conversion filter previously created by the developers. Developing an interface suitable for all different screen sizes was one of the biggest challenges of the project, but now the interface is suitable for most devices of sizes around 5-6 inches. Results The flick interface is estimated to significantly reduce the number of keypresses required to type an expression. The following table shows an estimated comparison for a few common expressions [1]. Mathematical expression Direct input taps Flick input taps x^2+5x+6 19 8 3x^2-\\frac{2x}{(x^2+1)^2} 36 13 2x \\cos(x^2) 23 7 Table: A comparison of the number of taps needed to type an expression. To analyse the usability of the interface, the developers conducted a usability test at Nagoya University, Japan. 29 students where asked to enter five common maths expressions by using both a traditional keyboard and the new flick input keyboard. After they entered these math expressions, they were given a survey on usability and satisfaction levels. The survey questions were based on the following five parameters, originally from Jakob Nielsen\u2019s five goals of usability [2]: learnability, efficiency, difficulty or ease in making corrections, rememberability, and the intent to reuse. For each parameter, students were asked to give each input type a score from 0.0 to 5.0. The following table shows the results [1], including both the averages, as well as the standard deviations in parentheses. The survey suggests that the usability and satisfaction levels are higher when the flick input method is used to enter mathematical expressions, rather than the direct input method. Question Direct input score Flick input score It is easy to learn how to input math. 3.0 (1.2) 3.5 (1.0) I can input math quickly and easily. 2.6 (1.1) 3.2 (1.3) It is not confusing and easy to correct. 3.0 (1.2) 3.1 (1.1) I remember the method that I learnt at the rehearsal. 3.0 (1.1) 3.1 (1.1) I will use this method to input math the next time 2.9 (1.3) 3.2 (1.4) Table: Responses from the interface survey. Standard deviations are given in parentheses. What's Next? The next step for the developers is to merge the flick interface into STACK as a new input type. This will include refactoring the flick interface code and working with STACK developers to best implement it into the question type. References [1] Y. Nakamura and T. Nakahara. A new mathematics input interface with flick operation for mobile devices. 15(2), 2017. [2] J. Nielsen. Usability Engineering. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1993. Adaptive Self-learning Exercises Innovating Education in Maseno, Kenya","title":"A Flick Interface for Maths Input"},{"location":"CaseStudies/2019/FlickInterface/#a-flick-interface-for-maths-input","text":"","title":"A Flick Interface for Maths Input"},{"location":"CaseStudies/2019/FlickInterface/#graduate-school-of-informatics-nagoya-university-japan","text":"Yasuyuki Nakamura Sangensha LLC., Japan Takahiro Nakahara","title":"Graduate School of Informatics, Nagoya University, Japan"},{"location":"CaseStudies/2019/FlickInterface/#abstract","text":"Typing mathematical expressions into mobile devices can be time-consuming. To solve this problem, developers at Nagoya University are developing a \"flick interface\" for STACK, similar to the popular Japanese keyboard mode. Students can pick a common integer or variable and flick in a direction to quickly turn, for example, x into \\sqrt(x) . A survey of usability suggests students prefer this input type to their traditional keyboard.","title":"Abstract"},{"location":"CaseStudies/2019/FlickInterface/#motivation","text":"As smartphones become increasingly used in schools and universities, it is important to find a reliable way to input mathematical expressions. Inputting mathematics on a computer is not a problem, but on smartphones and other mobile devices it can be much more time-consuming. For example, to type an answer to the question \"Expand (x+2)(x+3)\", students have to enter the expression x^2+5*x+6 into the answer space. On a mobile device, this requires several switches between the alphabetical and numerical views of the keyboard, resulting in 19 key touches for this simple answer. Recently, a flick keyboard for Japanese characters has become very popular in Japan, especially amongst young students. Japanese has three character systems. Hiragana is mostly used for simple and native Japanese words, katakana mostly for foreign words and kanji for all other words. The keyboard shows only a limited number of hiragana[^hiragana] characters, but students can hold and \"flick\" on a key to choose a similar character. Characters are grouped together by sound, for example grouping together na, ni, nu, ne and no. The keyboard will then suggest related kanji and/or katakana characters that share similar sounds. It was the popularity of this keyboard that motivated the developers to create a similar interface for inputting mathematics, as a STACK input type.","title":"Motivation"},{"location":"CaseStudies/2019/FlickInterface/#execution","text":"Figure: The flick interface in action. The flick interface was developed by Yasuyuki Nakamura and Takahiro Nakahara, funded by a grant from the Japan Society for the Promotion of Science. Like the Japanese character keyboard, students are faced with a small set of common inputs. Students can switch between numerical values and common variables by pressing \"123\" and \"xy\", respectively, or see a full keyboard view by clicking the keyboard logo. Pressing on a number reveals some common manipulations, and students can then flick in one direction to turn, for example, \"2\" into \"2x\". The input is compatible with normal keyboards, and will automatically be selected for the type of device being used. The interface is programmed in JavaScript to minimise the dependency on mobile device operating systems. The interface uses MathDox to describe expressions, and the input is then converted to the Maxima format by a conversion filter previously created by the developers. Developing an interface suitable for all different screen sizes was one of the biggest challenges of the project, but now the interface is suitable for most devices of sizes around 5-6 inches.","title":"Execution"},{"location":"CaseStudies/2019/FlickInterface/#results","text":"The flick interface is estimated to significantly reduce the number of keypresses required to type an expression. The following table shows an estimated comparison for a few common expressions [1]. Mathematical expression Direct input taps Flick input taps x^2+5x+6 19 8 3x^2-\\frac{2x}{(x^2+1)^2} 36 13 2x \\cos(x^2) 23 7 Table: A comparison of the number of taps needed to type an expression. To analyse the usability of the interface, the developers conducted a usability test at Nagoya University, Japan. 29 students where asked to enter five common maths expressions by using both a traditional keyboard and the new flick input keyboard. After they entered these math expressions, they were given a survey on usability and satisfaction levels. The survey questions were based on the following five parameters, originally from Jakob Nielsen\u2019s five goals of usability [2]: learnability, efficiency, difficulty or ease in making corrections, rememberability, and the intent to reuse. For each parameter, students were asked to give each input type a score from 0.0 to 5.0. The following table shows the results [1], including both the averages, as well as the standard deviations in parentheses. The survey suggests that the usability and satisfaction levels are higher when the flick input method is used to enter mathematical expressions, rather than the direct input method. Question Direct input score Flick input score It is easy to learn how to input math. 3.0 (1.2) 3.5 (1.0) I can input math quickly and easily. 2.6 (1.1) 3.2 (1.3) It is not confusing and easy to correct. 3.0 (1.2) 3.1 (1.1) I remember the method that I learnt at the rehearsal. 3.0 (1.1) 3.1 (1.1) I will use this method to input math the next time 2.9 (1.3) 3.2 (1.4) Table: Responses from the interface survey. Standard deviations are given in parentheses.","title":"Results"},{"location":"CaseStudies/2019/FlickInterface/#whats-next","text":"The next step for the developers is to merge the flick interface into STACK as a new input type. This will include refactoring the flick interface code and working with STACK developers to best implement it into the question type.","title":"What's Next?"},{"location":"CaseStudies/2019/FlickInterface/#references","text":"[1] Y. Nakamura and T. Nakahara. A new mathematics input interface with flick operation for mobile devices. 15(2), 2017. [2] J. Nielsen. Usability Engineering. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1993. Adaptive Self-learning Exercises Innovating Education in Maseno, Kenya","title":"References"},{"location":"CaseStudies/2019/ILIAS/","text":"Technical Integration of STACK into ILIAS Innovation in Learning Institute Interview with Fred Neumann and Jesus Copado Abstract STACK was integrated into the ILIAS learning management system to support projects for learning content. This was done by creating an integrated question type directly in ILIAS. The biggest challenges were decoupling the dependencies on Moodle, and an increasing number of user queries following a quickly growing community. Motivation ILIAS is one of the most popular Learning Management Systems (LMS) used in German universities. It has been available under an open-source license since 2000, and since then has grown in popularity in a number of countries, especially Germany and Switzerland. In the last decade, the ILIAS community started a special-interest group related to mathematical assessment. The main driver for this was the \"optes\" project, a federally funded project to create open learning content for mathematics and natural science. It was key for this project to have a sophisticated question system that uses CAS to evaluate students' input. In 2013, the group compared different systems for CAS based questions and finally decided to use STACK. STACK was initially built for the learning management system Moodle, and it would not be trivial to implement STACK into ILIAS. A crowd funding initiative was started to port the STACK plugin from Moodle to ILIAS, and the Innovation in Learning Institute at the Friedrich-Alexander-University Erlangen-Nuremberg (FAU) was asked to implement and maintain it. This would also be an advantage to FAU, as it could then establish STACK as an innovative element of e-learning and e-assessment at the University. Execution It was important to create an integrated question type that works like all the others in ILIAS, instead of trying to dynamically connect a separate STACK platform to ILIAS. Initially, a 2-day meeting with lead STACK developer Chris Sangwin was held at Loughborough University in December 2013, where the basic architecture and principles of the question type were laid out. In the following months, the ILIAS question type was created. The developers set up a Moodle installation with STACK, examined the code and analysed how it works. Then the \u2018library-like\u2019 Moodle core was extracted and integrated into the template of an ILIAS question plugin. The techniques used followed the open source nature of STACK and were supported by the fact that STACK uses the same technology (PHP/mySQL) as ILIAS. Initially, the only way to add questions was to create them in Moodle, then import the moodleXML file into ILIAS. However, authoring provisions and an authoring interface were later created in ILIAS, using the GUI classes. Results From the beginning, the ILIAS community has shown a great interest in using the integration of STACK. To date, nine separate institutions have participated in the crowd funding of the plugin. Over time, several workshops have been organized by the community. A German user manual and workshops to teach the creation of STACK questions was created at FAU and ported to an online module by the University of G\u00f6ttingen. In 2018, the first international STACK conference was held at the Innovation in Learning Institute, bringing together around 65 participants from the Moodle and ILIAS communities. As hoped, STACK is now being used extensively at FAU for innovative e-assessment. The ILIAS installation at FAU contains around 3000 questions from over 100 different authors. Additionally, a local \u2018STACK user group\u2019 was founded with 40 members from various disciplines, including mathematics, natural sciences, engineering, and economics. Based on external and internal funding, it is possible to permanently provide new major versions of the plugin for each major ILIAS release every year, as well as several minor bug fix versions in between. The core of STACK used by the plugin is also updated every year. The ILIAS questions are fully compatible with the Moodle version and can be exchanged between the two Learning Management Systems through the moodleXML format. Figure: A typical ILIAS question about simplification.. Challenges The biggest challenge for the initial integration of STACK into ILIAS was the decoupling of all dependencies from Moodle in the STACK core. Currently, around 50 patches are maintained for that. Furthermore, there were major differences in ILIAS and Moodle regarding the definition and display of feedback and various test player options. The completely different GUIs of Moodle and ILIAS meant the whole authoring interface of STACK had to be redesigned. When the community of STACK users in ILIAS grew, the number of bug reports related to exotic edge cases of STACK usage also grew. This could, for example, be issues relating to questions with a huge number of inputs. Furthermore, an increasing community of users brought in very different opinions about the styles of a question, its validation and feedback. Dealing with these issues was a significant challenge. A barrier that had to be evaluated is time. The initial work in integrating STACK into ILIAS took significant effort, and the project has to be continually maintained as bug fixes and project features are applied. It is estimated that, on average, 70% of a full-time employee's time is required to maintain the STACK developments for ILIAS. This is currently partially funded by the ILIAS community and the Innovation in Learning Institute. Server performance was an issue when it came to using STACK in large institutions. Maxima was designed as a desktop application, and so lacks a set of \u201cgood practice\u201d recommendations for hardware and configuration options depending on the expected load. To solve this, there are some initiatives such as the GoMaxima project from HAW Hamburg and an initiative at the University of G\u00f6ttingen for a docker swarm of Maxima pools. Enablers The meeting with the lead STACK developer was a major help in getting the project off on the right track. The comprehensive STACK documentation was also invaluable for understanding the question type. Additionally, the support from the ILIAS special interest group was invaluable. This group helped sketch the authoring interface in ILIAS, write documentation and organise the first workshops. It also helped moderate the discussion of feature requests from the ILIAS community and organise crowd funding for the maintenance of the plugin. Furthermore, since the Innovation in Learning Institution is not a mathematics institution, it was invaluable to get help from mathematicians to write good demonstration questions. Finally, the port was supported by the common technology of ILIAS and STACK and the fact Moodle and ILIAS have very similar quiz structures, and both treat STACK as a question plugin type. Implementation differences aside, the main principles are the same. What's Next? The ILIAS question type will continue to be updated as STACK, Moodle and ILIAS get updated. In particular, the way question types in ILIAS are implemented will change in a future ILIAS patch, which means the question type will have to be adapted accordingly. There are also plans to make STACK less dependent on the Moodle library. If this is successful, the ILIAS plugin will have to be largely rewritten (since it depends on the Moodle library), however the developers are optimistic. From writing the question type the first time around, they have gained invaluable experience. Furthermore, the authoring interface will not have to be rewritten. There are many wishes from the ILIAS community for new features to be implemented. Some of these are step-wise feedback, as well as more control of the feedback style, for example the colour of feedback boxes. These may be added to the STACK question type in the future. Finally, the maintenance relies heavily on crowdfunding managed between institutions (typically the Innovation in Learning Institution and another University). This means contracts have to be written between the heads of each institution, which can be difficult to manage. There are therefore considerations to transfer the maintenance of the question type to an ILIAS service provider, as it would then be easier to get crowdfunding contracts from Universities. optes: Optimising Self-study With STACK STACK at Scale: The Open University","title":"Technical Integration of STACK into ILIAS"},{"location":"CaseStudies/2019/ILIAS/#technical-integration-of-stack-into-ilias","text":"","title":"Technical Integration of STACK into ILIAS"},{"location":"CaseStudies/2019/ILIAS/#innovation-in-learning-institute","text":"Interview with Fred Neumann and Jesus Copado","title":"Innovation in Learning Institute"},{"location":"CaseStudies/2019/ILIAS/#abstract","text":"STACK was integrated into the ILIAS learning management system to support projects for learning content. This was done by creating an integrated question type directly in ILIAS. The biggest challenges were decoupling the dependencies on Moodle, and an increasing number of user queries following a quickly growing community.","title":"Abstract"},{"location":"CaseStudies/2019/ILIAS/#motivation","text":"ILIAS is one of the most popular Learning Management Systems (LMS) used in German universities. It has been available under an open-source license since 2000, and since then has grown in popularity in a number of countries, especially Germany and Switzerland. In the last decade, the ILIAS community started a special-interest group related to mathematical assessment. The main driver for this was the \"optes\" project, a federally funded project to create open learning content for mathematics and natural science. It was key for this project to have a sophisticated question system that uses CAS to evaluate students' input. In 2013, the group compared different systems for CAS based questions and finally decided to use STACK. STACK was initially built for the learning management system Moodle, and it would not be trivial to implement STACK into ILIAS. A crowd funding initiative was started to port the STACK plugin from Moodle to ILIAS, and the Innovation in Learning Institute at the Friedrich-Alexander-University Erlangen-Nuremberg (FAU) was asked to implement and maintain it. This would also be an advantage to FAU, as it could then establish STACK as an innovative element of e-learning and e-assessment at the University.","title":"Motivation"},{"location":"CaseStudies/2019/ILIAS/#execution","text":"It was important to create an integrated question type that works like all the others in ILIAS, instead of trying to dynamically connect a separate STACK platform to ILIAS. Initially, a 2-day meeting with lead STACK developer Chris Sangwin was held at Loughborough University in December 2013, where the basic architecture and principles of the question type were laid out. In the following months, the ILIAS question type was created. The developers set up a Moodle installation with STACK, examined the code and analysed how it works. Then the \u2018library-like\u2019 Moodle core was extracted and integrated into the template of an ILIAS question plugin. The techniques used followed the open source nature of STACK and were supported by the fact that STACK uses the same technology (PHP/mySQL) as ILIAS. Initially, the only way to add questions was to create them in Moodle, then import the moodleXML file into ILIAS. However, authoring provisions and an authoring interface were later created in ILIAS, using the GUI classes.","title":"Execution"},{"location":"CaseStudies/2019/ILIAS/#results","text":"From the beginning, the ILIAS community has shown a great interest in using the integration of STACK. To date, nine separate institutions have participated in the crowd funding of the plugin. Over time, several workshops have been organized by the community. A German user manual and workshops to teach the creation of STACK questions was created at FAU and ported to an online module by the University of G\u00f6ttingen. In 2018, the first international STACK conference was held at the Innovation in Learning Institute, bringing together around 65 participants from the Moodle and ILIAS communities. As hoped, STACK is now being used extensively at FAU for innovative e-assessment. The ILIAS installation at FAU contains around 3000 questions from over 100 different authors. Additionally, a local \u2018STACK user group\u2019 was founded with 40 members from various disciplines, including mathematics, natural sciences, engineering, and economics. Based on external and internal funding, it is possible to permanently provide new major versions of the plugin for each major ILIAS release every year, as well as several minor bug fix versions in between. The core of STACK used by the plugin is also updated every year. The ILIAS questions are fully compatible with the Moodle version and can be exchanged between the two Learning Management Systems through the moodleXML format. Figure: A typical ILIAS question about simplification..","title":"Results"},{"location":"CaseStudies/2019/ILIAS/#challenges","text":"The biggest challenge for the initial integration of STACK into ILIAS was the decoupling of all dependencies from Moodle in the STACK core. Currently, around 50 patches are maintained for that. Furthermore, there were major differences in ILIAS and Moodle regarding the definition and display of feedback and various test player options. The completely different GUIs of Moodle and ILIAS meant the whole authoring interface of STACK had to be redesigned. When the community of STACK users in ILIAS grew, the number of bug reports related to exotic edge cases of STACK usage also grew. This could, for example, be issues relating to questions with a huge number of inputs. Furthermore, an increasing community of users brought in very different opinions about the styles of a question, its validation and feedback. Dealing with these issues was a significant challenge. A barrier that had to be evaluated is time. The initial work in integrating STACK into ILIAS took significant effort, and the project has to be continually maintained as bug fixes and project features are applied. It is estimated that, on average, 70% of a full-time employee's time is required to maintain the STACK developments for ILIAS. This is currently partially funded by the ILIAS community and the Innovation in Learning Institute. Server performance was an issue when it came to using STACK in large institutions. Maxima was designed as a desktop application, and so lacks a set of \u201cgood practice\u201d recommendations for hardware and configuration options depending on the expected load. To solve this, there are some initiatives such as the GoMaxima project from HAW Hamburg and an initiative at the University of G\u00f6ttingen for a docker swarm of Maxima pools.","title":"Challenges"},{"location":"CaseStudies/2019/ILIAS/#enablers","text":"The meeting with the lead STACK developer was a major help in getting the project off on the right track. The comprehensive STACK documentation was also invaluable for understanding the question type. Additionally, the support from the ILIAS special interest group was invaluable. This group helped sketch the authoring interface in ILIAS, write documentation and organise the first workshops. It also helped moderate the discussion of feature requests from the ILIAS community and organise crowd funding for the maintenance of the plugin. Furthermore, since the Innovation in Learning Institution is not a mathematics institution, it was invaluable to get help from mathematicians to write good demonstration questions. Finally, the port was supported by the common technology of ILIAS and STACK and the fact Moodle and ILIAS have very similar quiz structures, and both treat STACK as a question plugin type. Implementation differences aside, the main principles are the same.","title":"Enablers"},{"location":"CaseStudies/2019/ILIAS/#whats-next","text":"The ILIAS question type will continue to be updated as STACK, Moodle and ILIAS get updated. In particular, the way question types in ILIAS are implemented will change in a future ILIAS patch, which means the question type will have to be adapted accordingly. There are also plans to make STACK less dependent on the Moodle library. If this is successful, the ILIAS plugin will have to be largely rewritten (since it depends on the Moodle library), however the developers are optimistic. From writing the question type the first time around, they have gained invaluable experience. Furthermore, the authoring interface will not have to be rewritten. There are many wishes from the ILIAS community for new features to be implemented. Some of these are step-wise feedback, as well as more control of the feedback style, for example the colour of feedback boxes. These may be added to the STACK question type in the future. Finally, the maintenance relies heavily on crowdfunding managed between institutions (typically the Innovation in Learning Institution and another University). This means contracts have to be written between the heads of each institution, which can be difficult to manage. There are therefore considerations to transfer the maintenance of the question type to an ILIAS service provider, as it would then be easier to get crowdfunding contracts from Universities. optes: Optimising Self-study With STACK STACK at Scale: The Open University","title":"What's Next?"},{"location":"CaseStudies/2019/Loughborough/","text":"Promoting STACK Across Disciplines at Loughborough University Loughborough University Ian Jones Abstract At Loughborough University, STACK has been implemented across many disciplines. Courses are created by module leaders, who prepare paper-based problems, and academics and students who implement these problems in STACK. To promote STACK to lecturers across the University, a showcase module page was developed that makes it easy to navigate and browse good STACK examples across disciplines. Introduction STACK was installed at Loughborough University in 2014. Since then, a programme of development and dissemination led by Loughborough\u2019s Mathematics Education Centre has resulted in widespread use across the University. The University has encouraged multidisciplinary take up beyond the mathematics department, and now 57 modules across six degree programmes include STACK content. STACK is used for assessment in topics including mathematics, business, statistics, chemical engineering, physics and foundation programmes. Execution Initially, questions were developed in conjunction with module leaders. Typically a module leader provided the developers with paper-based problem sheets. The developers, who included academics as well as PhD and undergraduate mathematics students working on projects, adapted the problems into STACK questions. The example below illustrates how the developers paid special attention to making use of STACK\u2019s unique feedback feature to provide personalised feedback to students. Figure: A paper-based question and its STACK equivalent. Alongside development, the STACK content was promoted and disseminated to lecturers across the University via internal workshops. This included workshops to train module leaders in developing their own content. Additionally, a module page was developed, viewable to all teaching staff, that acts as a showcase for STACK content. Figure: The University developed a showcase module page. The showcase module page is designed to be easy to use and navigate, even for beginners. This is because newcomers often find navigating, selecting and exporting questions off-putting. To overcome this, all questions within a topic have been wrapped into a downloadable .zip file, and only a few navigable example questions have been provided. The download screen for business-based STACK questions is shown below. Business questions have been a particular success, and a new project to develop further STACK content for the School of Business and Economics begins in Autumn 2019. Figure: The download screen for a collection of business STACK questions. What's Next? STACK development continues at Loughborough. The University continues to be particularly interested in promoting STACK in areas where it is not commonly used. This development includes developing STACK content for degree programmes beyond mathematics, such as statistics for psychologists, as well as areas within mathematics that are traditionally difficult to assess automatically. A particularly exciting area being explored is assessing proof comprehension, and an example prototype question is shown below. Figure: A STACK question assessing some skills in proof comprehension. STACK for Engineering Mathematics and the Abacus Material Bank Institutional Support for STACK in Edinburgh","title":"Promoting STACK Across Disciplines at Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#promoting-stack-across-disciplines-at-loughborough-university","text":"","title":"Promoting STACK Across Disciplines at Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#loughborough-university","text":"Ian Jones","title":"Loughborough University"},{"location":"CaseStudies/2019/Loughborough/#abstract","text":"At Loughborough University, STACK has been implemented across many disciplines. Courses are created by module leaders, who prepare paper-based problems, and academics and students who implement these problems in STACK. To promote STACK to lecturers across the University, a showcase module page was developed that makes it easy to navigate and browse good STACK examples across disciplines.","title":"Abstract"},{"location":"CaseStudies/2019/Loughborough/#introduction","text":"STACK was installed at Loughborough University in 2014. Since then, a programme of development and dissemination led by Loughborough\u2019s Mathematics Education Centre has resulted in widespread use across the University. The University has encouraged multidisciplinary take up beyond the mathematics department, and now 57 modules across six degree programmes include STACK content. STACK is used for assessment in topics including mathematics, business, statistics, chemical engineering, physics and foundation programmes.","title":"Introduction"},{"location":"CaseStudies/2019/Loughborough/#execution","text":"Initially, questions were developed in conjunction with module leaders. Typically a module leader provided the developers with paper-based problem sheets. The developers, who included academics as well as PhD and undergraduate mathematics students working on projects, adapted the problems into STACK questions. The example below illustrates how the developers paid special attention to making use of STACK\u2019s unique feedback feature to provide personalised feedback to students. Figure: A paper-based question and its STACK equivalent. Alongside development, the STACK content was promoted and disseminated to lecturers across the University via internal workshops. This included workshops to train module leaders in developing their own content. Additionally, a module page was developed, viewable to all teaching staff, that acts as a showcase for STACK content. Figure: The University developed a showcase module page. The showcase module page is designed to be easy to use and navigate, even for beginners. This is because newcomers often find navigating, selecting and exporting questions off-putting. To overcome this, all questions within a topic have been wrapped into a downloadable .zip file, and only a few navigable example questions have been provided. The download screen for business-based STACK questions is shown below. Business questions have been a particular success, and a new project to develop further STACK content for the School of Business and Economics begins in Autumn 2019. Figure: The download screen for a collection of business STACK questions.","title":"Execution"},{"location":"CaseStudies/2019/Loughborough/#whats-next","text":"STACK development continues at Loughborough. The University continues to be particularly interested in promoting STACK in areas where it is not commonly used. This development includes developing STACK content for degree programmes beyond mathematics, such as statistics for psychologists, as well as areas within mathematics that are traditionally difficult to assess automatically. A particularly exciting area being explored is assessing proof comprehension, and an example prototype question is shown below. Figure: A STACK question assessing some skills in proof comprehension. STACK for Engineering Mathematics and the Abacus Material Bank Institutional Support for STACK in Edinburgh","title":"What's Next?"},{"location":"CaseStudies/2019/Maseno/","text":"Innovating Education in Maseno, Kenya Maseno University, Kenya Santiago Borio, IDEMS Michael Obiero Oyengo, Maseno University Abstract IDEMS International is working with Maseno University to implement online assessment for their mathematics courses. Developers from IDEMS and Maseno University created online quizzes for two courses during the pilot of the project, running on servers at the University of Edinburgh. The main challenges of the project were related to poor student access to WiFi and time pressure for the question authors. The feedback from the students was mostly positive, and the pilot paves the way for more similar work in the future. This includes online assessment for many more courses at Maseno University, as well as collaborations with other African universities and secondary schools. Introduction IDEMS International (Innovations on Development, Education and the Mathematical Sciences) is a Community Interest Company working to support different development causes, mostly in Africa, in fields of education and mathematical sciences. The non-profit organisation generates open education resources and offers services to Universities and other institutions. One of their projects was to help implement Computer Aided Assessment (CAA) in African Universities, of which Maseno University was chosen as a pilot. Maseno University, Kenya, has a large number of students in its undergraduate mathematics courses, many courses having 800 enrolled students and some more than 1000, but there is little support for lecturers in terms of marking. This puts pressure on their ability to reliably do weekly assessments for students. By changing the continuous assessment from a paper format to an electronic system, the hope was that lecturers would have more opportunities to concentrate on their teaching and supporting students in other ways. Figure: Maseno University. Why Use STACK? There were a number of reasons for why STACK was chosen for this project. Firstly, there was already some familiarity with the STACK system within IDEMS, as one of the contributors had previously worked with STACK question authoring. Secondly, the main STACK developer offered assistance, including the opportunity to run the service on servers at the University of Edinburgh. Finally, having compared STACK with other systems, the developers found that the flexibility in answer tests, recognition of mistakes through potential response trees and the ability to have questions that require numerical or algebraic input for answers made STACK more powerful than the alternatives. Execution Figure: A STACK question from \"Calculus I\" involving continuity and L'H\u00f4pital's rule. The developers from IDEMS and Maseno University created online STACK quizzes for the courses \"Calculus I\" and \"Introduction to Linear Algebra\". In the case of \"Calculus I\", the main lecturer provided a written quiz structure and list of questions, so the main work was just typing these into STACK and implementing randomisation. In contrast, the quizzes of \"Introduction to Linear Algebra\" were written mostly from scratch, only using a few questions from the STACK sample materials. Initially, students are given a syntax quiz to learn the STACK syntax, and then in each of the following 10 weeks they are given a formative \"mastery quiz\" and a summative \"test quiz\". The mastery quiz can be taken as many times as the students wants, but they must get a score of 80% in the mastery quiz to unlock the respective test quiz, where students are only given one attempt. In \"Introduction to Linear Algebra\", this restriction was later reduced to 70%, as lecturers felt students were having a hard time keeping up with materials. The mastery and test quizzes together count for 30% of the students course grade. Towards the end of the course there is also a review week with STACK questions, and in \"Introduction to Linear Algebra\" students can take an online practice exam. Feedback After the first year, the students of the two courses were asked to fill out a survey about their experience with STACK. The first few questions regarded accessing the course. Maseno University does not have reliable WiFi, and it is not common for students' accommodation to have WiFi either. As a result, most students had to use either their own or a friends' phone, and purchase a data package to access the course. Indeed, when asked to rate the difficulty of different aspects, many students ranked \"accessing the internet\" in the range of \"slightly challenging\" to \"very challenging\". Figure: Responses to the survey for \"Introductory Linear Algebra\". When asked to rate how helpful they found different aspects of the assessments, many students ranked getting feedback, being able to have multiple attempts at mastery quizzes, having weekly quizzes and having the mastery quizzes open all semester as useful. Most students did not seem to have too much difficulty with the STACK syntax, ranking it in a range of \"not a challenge\" to \"moderately challenging\". This was surely helped by the attempts to ensure students were learning the syntax, for example through the introductory syntax quiz. However, it also seems there is room for improvement here. The students were also given an opportunity to add any general comments or suggestions. The majority of these answers were from students who were happy with STACK and said it was useful for getting a deeper understanding of the material. With regards to quizzes, many students requested more than one attempt at test quizzes, with extended deadlines. They requested more mastery quizzes, suggesting they found them helpful, and some students suggested access to harder, exam-style questions. There were also some comments about the feedback for questions. Due to time constraints, the calculus course only had feedback in the form of worked solutions, and for linear algebra, students were only given outlines to solutions. Students said that they wanted better feedback, and so one of the goals for the next iteration will be to add tailored feedback to all questions. Finally, there was a call to improve accessibility for the visually impaired. Challenges As is evident from the survey responses, there was a challenge regarding the students' access to internet. However, this did not end up being as big a problem as anticipated, as students seemed able and willing to pay for data packages to access the course. Furthermore, due to the short term allocation of courses and lecturers, there was a significant time pressure for writing the quizzes. As a result, there was no time to implement tailored feedback, and a number of quizzes were delivered late. However, this did not seem to discourage students or create major issues in the completion of quizzes. Enablers A major enabler for the project was the ability of IDEMS to assist the University in question authoring. The questions were written by Michael Obiero Oyengo and David Ambogo from Maseno University and Santiago Borio, Danny Parsons and David Stern from IDEMS. Additionally, the main STACK developer C. Sangwin helped give crash courses in using STACK, which sped up the learning process. The course was also run on a server at the University of Edinburgh, which meant the developers did not have to worry about setting up a server and could focus entirely on question authoring. Finally, the STACK sample questions helped speed up the question authoring process, as the developers could use them as templates when writing similar questions. What's Next? Following the success of this pilot course, IDEMS is looking to expand into similar projects. The first step will be improving the two initial courses. Once the analysis of the data from the pilot course is finished, it will be possible to identify the main areas that need work. These two courses have been transferred to an IDEMS server, so they can be easily used for online assessment at other universities. The server will be built to cope with universities with many students, as IDEMS expects to use it for some courses with more than 1000 students. A number of Universities have expressed interest in this project, including universities from Kenya, Ethiopia, Rwanda, Tanzania and Uganda. In particular, the mathematics department at Bahir Dar University, Ethiopia has agreed to investigate implementing a number of IDEMS' courses. In August 2019, IDEMS is holding a workshop , where representatives from these universities will discuss STACK and how to best implement e-assessment at their institutions. The 5-day workshop will include talks on the advantages of using online assessment, as well as practical work to prepare lecturers who want to use IDEMS' online course material. The workshop is funded by a grant from the Commission for Developing Countries (CDC) of the International Mathematical Union. IDEMS is also helping Maseno University create online materials for several of its other courses. In the 19/20 term, Maseno University will run the improved \"Calculus I\", as well as five other courses with online assessment: \"Descriptive Statistics\", \"Introduction to Probability Theory\", \"Basic Mathematics\", \"Calculus II\" and \"Vector Analysis\". For these courses, IDEMS will be training some lecturers to author their own questions, which will increase their control of the online quizzes. As with the two pilot courses, these courses are planned to be piloted at Maseno University first, then refined based on feedback and made available as an OER for other universities. Finally, IDEMS is looking at using STACK in secondary schools. There are plans to develop an e-book for African schools with accompanying STACK questions, including an offline system for schools with poor WiFi. IDEMS is also evaluating opportunities to develop an open assessment system for English schools. A Flick Interface for Maths Input optes: Optimising Self-study With STACK","title":"Innovating Education in Maseno, Kenya"},{"location":"CaseStudies/2019/Maseno/#innovating-education-in-maseno-kenya","text":"","title":"Innovating Education in Maseno, Kenya"},{"location":"CaseStudies/2019/Maseno/#maseno-university-kenya","text":"Santiago Borio, IDEMS Michael Obiero Oyengo, Maseno University","title":"Maseno University, Kenya"},{"location":"CaseStudies/2019/Maseno/#abstract","text":"IDEMS International is working with Maseno University to implement online assessment for their mathematics courses. Developers from IDEMS and Maseno University created online quizzes for two courses during the pilot of the project, running on servers at the University of Edinburgh. The main challenges of the project were related to poor student access to WiFi and time pressure for the question authors. The feedback from the students was mostly positive, and the pilot paves the way for more similar work in the future. This includes online assessment for many more courses at Maseno University, as well as collaborations with other African universities and secondary schools.","title":"Abstract"},{"location":"CaseStudies/2019/Maseno/#introduction","text":"IDEMS International (Innovations on Development, Education and the Mathematical Sciences) is a Community Interest Company working to support different development causes, mostly in Africa, in fields of education and mathematical sciences. The non-profit organisation generates open education resources and offers services to Universities and other institutions. One of their projects was to help implement Computer Aided Assessment (CAA) in African Universities, of which Maseno University was chosen as a pilot. Maseno University, Kenya, has a large number of students in its undergraduate mathematics courses, many courses having 800 enrolled students and some more than 1000, but there is little support for lecturers in terms of marking. This puts pressure on their ability to reliably do weekly assessments for students. By changing the continuous assessment from a paper format to an electronic system, the hope was that lecturers would have more opportunities to concentrate on their teaching and supporting students in other ways. Figure: Maseno University.","title":"Introduction"},{"location":"CaseStudies/2019/Maseno/#why-use-stack","text":"There were a number of reasons for why STACK was chosen for this project. Firstly, there was already some familiarity with the STACK system within IDEMS, as one of the contributors had previously worked with STACK question authoring. Secondly, the main STACK developer offered assistance, including the opportunity to run the service on servers at the University of Edinburgh. Finally, having compared STACK with other systems, the developers found that the flexibility in answer tests, recognition of mistakes through potential response trees and the ability to have questions that require numerical or algebraic input for answers made STACK more powerful than the alternatives.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/Maseno/#execution","text":"Figure: A STACK question from \"Calculus I\" involving continuity and L'H\u00f4pital's rule. The developers from IDEMS and Maseno University created online STACK quizzes for the courses \"Calculus I\" and \"Introduction to Linear Algebra\". In the case of \"Calculus I\", the main lecturer provided a written quiz structure and list of questions, so the main work was just typing these into STACK and implementing randomisation. In contrast, the quizzes of \"Introduction to Linear Algebra\" were written mostly from scratch, only using a few questions from the STACK sample materials. Initially, students are given a syntax quiz to learn the STACK syntax, and then in each of the following 10 weeks they are given a formative \"mastery quiz\" and a summative \"test quiz\". The mastery quiz can be taken as many times as the students wants, but they must get a score of 80% in the mastery quiz to unlock the respective test quiz, where students are only given one attempt. In \"Introduction to Linear Algebra\", this restriction was later reduced to 70%, as lecturers felt students were having a hard time keeping up with materials. The mastery and test quizzes together count for 30% of the students course grade. Towards the end of the course there is also a review week with STACK questions, and in \"Introduction to Linear Algebra\" students can take an online practice exam.","title":"Execution"},{"location":"CaseStudies/2019/Maseno/#feedback","text":"After the first year, the students of the two courses were asked to fill out a survey about their experience with STACK. The first few questions regarded accessing the course. Maseno University does not have reliable WiFi, and it is not common for students' accommodation to have WiFi either. As a result, most students had to use either their own or a friends' phone, and purchase a data package to access the course. Indeed, when asked to rate the difficulty of different aspects, many students ranked \"accessing the internet\" in the range of \"slightly challenging\" to \"very challenging\". Figure: Responses to the survey for \"Introductory Linear Algebra\". When asked to rate how helpful they found different aspects of the assessments, many students ranked getting feedback, being able to have multiple attempts at mastery quizzes, having weekly quizzes and having the mastery quizzes open all semester as useful. Most students did not seem to have too much difficulty with the STACK syntax, ranking it in a range of \"not a challenge\" to \"moderately challenging\". This was surely helped by the attempts to ensure students were learning the syntax, for example through the introductory syntax quiz. However, it also seems there is room for improvement here. The students were also given an opportunity to add any general comments or suggestions. The majority of these answers were from students who were happy with STACK and said it was useful for getting a deeper understanding of the material. With regards to quizzes, many students requested more than one attempt at test quizzes, with extended deadlines. They requested more mastery quizzes, suggesting they found them helpful, and some students suggested access to harder, exam-style questions. There were also some comments about the feedback for questions. Due to time constraints, the calculus course only had feedback in the form of worked solutions, and for linear algebra, students were only given outlines to solutions. Students said that they wanted better feedback, and so one of the goals for the next iteration will be to add tailored feedback to all questions. Finally, there was a call to improve accessibility for the visually impaired.","title":"Feedback"},{"location":"CaseStudies/2019/Maseno/#challenges","text":"As is evident from the survey responses, there was a challenge regarding the students' access to internet. However, this did not end up being as big a problem as anticipated, as students seemed able and willing to pay for data packages to access the course. Furthermore, due to the short term allocation of courses and lecturers, there was a significant time pressure for writing the quizzes. As a result, there was no time to implement tailored feedback, and a number of quizzes were delivered late. However, this did not seem to discourage students or create major issues in the completion of quizzes.","title":"Challenges"},{"location":"CaseStudies/2019/Maseno/#enablers","text":"A major enabler for the project was the ability of IDEMS to assist the University in question authoring. The questions were written by Michael Obiero Oyengo and David Ambogo from Maseno University and Santiago Borio, Danny Parsons and David Stern from IDEMS. Additionally, the main STACK developer C. Sangwin helped give crash courses in using STACK, which sped up the learning process. The course was also run on a server at the University of Edinburgh, which meant the developers did not have to worry about setting up a server and could focus entirely on question authoring. Finally, the STACK sample questions helped speed up the question authoring process, as the developers could use them as templates when writing similar questions.","title":"Enablers"},{"location":"CaseStudies/2019/Maseno/#whats-next","text":"Following the success of this pilot course, IDEMS is looking to expand into similar projects. The first step will be improving the two initial courses. Once the analysis of the data from the pilot course is finished, it will be possible to identify the main areas that need work. These two courses have been transferred to an IDEMS server, so they can be easily used for online assessment at other universities. The server will be built to cope with universities with many students, as IDEMS expects to use it for some courses with more than 1000 students. A number of Universities have expressed interest in this project, including universities from Kenya, Ethiopia, Rwanda, Tanzania and Uganda. In particular, the mathematics department at Bahir Dar University, Ethiopia has agreed to investigate implementing a number of IDEMS' courses. In August 2019, IDEMS is holding a workshop , where representatives from these universities will discuss STACK and how to best implement e-assessment at their institutions. The 5-day workshop will include talks on the advantages of using online assessment, as well as practical work to prepare lecturers who want to use IDEMS' online course material. The workshop is funded by a grant from the Commission for Developing Countries (CDC) of the International Mathematical Union. IDEMS is also helping Maseno University create online materials for several of its other courses. In the 19/20 term, Maseno University will run the improved \"Calculus I\", as well as five other courses with online assessment: \"Descriptive Statistics\", \"Introduction to Probability Theory\", \"Basic Mathematics\", \"Calculus II\" and \"Vector Analysis\". For these courses, IDEMS will be training some lecturers to author their own questions, which will increase their control of the online quizzes. As with the two pilot courses, these courses are planned to be piloted at Maseno University first, then refined based on feedback and made available as an OER for other universities. Finally, IDEMS is looking at using STACK in secondary schools. There are plans to develop an e-book for African schools with accompanying STACK questions, including an offline system for schools with poor WiFi. IDEMS is also evaluating opportunities to develop an open assessment system for English schools. A Flick Interface for Maths Input optes: Optimising Self-study With STACK","title":"What's Next?"},{"location":"CaseStudies/2019/PhysicsCurriculum/","text":"STACK for a Physics Textbook Physics Curriculum & Instruction David Hilsen Abstract The commercial textbook publisher, Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook [1]. These make significant use of random variants and intermediate problem-solving steps. It was important to have feedback on problem design from academic colleagues, and to have support for significant figures and scientific units in STACK. The question bank will contain 3500 questions by the start of the 2019/20 school year. Motivation Physics Curriculum & Instruction is a Minnesota-based company providing schools with learning resources for Physics. With a lot of open-source options becoming available, putting resources into developing a commercial textbook can carry a significant risk. Physics Curriculum hopes to address this by directing their development efforts towards online physics educational resources. It was important to have a system that allowed them to address the wide variety of needs of instructors and that utilised randomization of numerical values. This makes it nearly impossible to search online for the answer to a particular problem; a major concern for publishers. Execution Figure: A Physics Curriculum question involving intermediate problem-solving steps. A large collection of online STACK questions were developed to accompany the book Physics Fundamentals [1]. Access to the online homework package can be purchased along with the book for an extra fee. The online questions are managed in the online learning environment Physics LE, which runs on Moodle. Moodle was picked for its Enrolment key feature and its Adaptive mode question behaviour that allows students to make multiple question attempts with immediate feedback. The team had four people authoring STACK questions, and two additional people working on Moodle and the cloud servers. Authoring questions required an average of just over one hour per question with a significant portion of that time devoted to quality control and testing. Ultimately the development sums to a significant financial investment, but also one that leaves an end product of high quality. A significant focus in the authoring of questions was on intermediate problem-solving steps, and which ones would be most beneficial to help the student formulate a problem-solving strategy. It was important to go beyond a system in which students simply enters a final numerical value that is marked right or wrong with no additional feedback. The intermediate problem-solving steps used are of the following type: multiple-choice questions, using text or diagrams, checking for understanding and problem-solving approach, input of relevant equations or algebraic expressions, input of intermediate numerical values which need to be calculated to obtain the final answer. Results The service went live in January 2019. Since then, 15 schools, both high schools and colleges, have urchased the online question package. Instructors gave positive feedback, especially appreciating the multiple-part question structure where students are given specific feedback. Barriers Figure: A Physics Curriculum question involving potential energy. Initially, there was no provision in STACK for handling significant figures, and limited support for physical units. This was a big barrier for Physics question authoring, and hence a more robust system was developed for this purpose. Additionally, high school students sometimes struggle with the syntax for equation input, especially those with minimal computer background. This continues to improve within STACK and may not be a concern in the future. Enablers Instructors and colleagues provided feedback from an outside perspective indicating where students might have difficulty. This encouraged the authoring of additional PRT nodes, for example checking for a particular misconception. What's Next? There are many additional schools evaluating the Physics Curriculum online homework system, and additional schools are expected to join. Furthermore, the question bank continues to grow. By the start of the 2019/20 school year, Physics Curriculum plans to have 3500 STACK problems in their system, many of these multiple-part. There are also plans to partner up with OpenStax, a company producing high quality College Physics textbooks, to bring them an affordable online homework solution as well. References [1] V. P. Coletta. Physics Fundamentals. Physics Curriculum and Instruction Inc., Lakeville, Minessota, 2nd edition, 2010. Developing a Fully Online Course Adaptive Self-learning Exercises","title":"STACK for a Physics Textbook"},{"location":"CaseStudies/2019/PhysicsCurriculum/#stack-for-a-physics-textbook","text":"","title":"STACK for a Physics Textbook"},{"location":"CaseStudies/2019/PhysicsCurriculum/#physics-curriculum-instruction","text":"David Hilsen","title":"Physics Curriculum &amp; Instruction"},{"location":"CaseStudies/2019/PhysicsCurriculum/#abstract","text":"The commercial textbook publisher, Physics Curriculum & Instruction have developed STACK questions to accompany a Physics textbook [1]. These make significant use of random variants and intermediate problem-solving steps. It was important to have feedback on problem design from academic colleagues, and to have support for significant figures and scientific units in STACK. The question bank will contain 3500 questions by the start of the 2019/20 school year.","title":"Abstract"},{"location":"CaseStudies/2019/PhysicsCurriculum/#motivation","text":"Physics Curriculum & Instruction is a Minnesota-based company providing schools with learning resources for Physics. With a lot of open-source options becoming available, putting resources into developing a commercial textbook can carry a significant risk. Physics Curriculum hopes to address this by directing their development efforts towards online physics educational resources. It was important to have a system that allowed them to address the wide variety of needs of instructors and that utilised randomization of numerical values. This makes it nearly impossible to search online for the answer to a particular problem; a major concern for publishers.","title":"Motivation"},{"location":"CaseStudies/2019/PhysicsCurriculum/#execution","text":"Figure: A Physics Curriculum question involving intermediate problem-solving steps. A large collection of online STACK questions were developed to accompany the book Physics Fundamentals [1]. Access to the online homework package can be purchased along with the book for an extra fee. The online questions are managed in the online learning environment Physics LE, which runs on Moodle. Moodle was picked for its Enrolment key feature and its Adaptive mode question behaviour that allows students to make multiple question attempts with immediate feedback. The team had four people authoring STACK questions, and two additional people working on Moodle and the cloud servers. Authoring questions required an average of just over one hour per question with a significant portion of that time devoted to quality control and testing. Ultimately the development sums to a significant financial investment, but also one that leaves an end product of high quality. A significant focus in the authoring of questions was on intermediate problem-solving steps, and which ones would be most beneficial to help the student formulate a problem-solving strategy. It was important to go beyond a system in which students simply enters a final numerical value that is marked right or wrong with no additional feedback. The intermediate problem-solving steps used are of the following type: multiple-choice questions, using text or diagrams, checking for understanding and problem-solving approach, input of relevant equations or algebraic expressions, input of intermediate numerical values which need to be calculated to obtain the final answer.","title":"Execution"},{"location":"CaseStudies/2019/PhysicsCurriculum/#results","text":"The service went live in January 2019. Since then, 15 schools, both high schools and colleges, have urchased the online question package. Instructors gave positive feedback, especially appreciating the multiple-part question structure where students are given specific feedback.","title":"Results"},{"location":"CaseStudies/2019/PhysicsCurriculum/#barriers","text":"Figure: A Physics Curriculum question involving potential energy. Initially, there was no provision in STACK for handling significant figures, and limited support for physical units. This was a big barrier for Physics question authoring, and hence a more robust system was developed for this purpose. Additionally, high school students sometimes struggle with the syntax for equation input, especially those with minimal computer background. This continues to improve within STACK and may not be a concern in the future.","title":"Barriers"},{"location":"CaseStudies/2019/PhysicsCurriculum/#enablers","text":"Instructors and colleagues provided feedback from an outside perspective indicating where students might have difficulty. This encouraged the authoring of additional PRT nodes, for example checking for a particular misconception.","title":"Enablers"},{"location":"CaseStudies/2019/PhysicsCurriculum/#whats-next","text":"There are many additional schools evaluating the Physics Curriculum online homework system, and additional schools are expected to join. Furthermore, the question bank continues to grow. By the start of the 2019/20 school year, Physics Curriculum plans to have 3500 STACK problems in their system, many of these multiple-part. There are also plans to partner up with OpenStax, a company producing high quality College Physics textbooks, to bring them an affordable online homework solution as well.","title":"What's Next?"},{"location":"CaseStudies/2019/PhysicsCurriculum/#references","text":"[1] V. P. Coletta. Physics Fundamentals. Physics Curriculum and Instruction Inc., Lakeville, Minessota, 2nd edition, 2010. Developing a Fully Online Course Adaptive Self-learning Exercises","title":"References"},{"location":"CaseStudies/2019/StackAtScale/","text":"STACK at Scale: The Open University The Open University. Tim Lowe, School of Mathematics and Statistics, Tim Hunt, Information Technology. Introduction Figure: The Open University. The Open University is the UK\u2019s largest academic institution. In 2017/18 there were approximately 175,000 students studying with the University, mainly part time, making approximately 65,000 full-time equivalent students. Students combine their study with work, family, caring and other responsibilities. Students study from home, at a distance, guided by the University\u2019s Moodle-based VLE and using a combination of online and printed materials. Students are supported by a tutor who provides individual support to a group of typically 20 students and usually offers a combination of face-to-face and online tutorial support. The School of Mathematics and Statistics offers a number of undergraduate qualifications in mathematics (with a total intake of approximately 1300 each year) and a taught MSc, which is the largest such course in the UK. In addition, students throughout the University can take one or more mathematics modules in support of their main subject of study. There are approximately 13,000 student-module combinations within mathematics and statistics each year. STACK is an ideal tool to support the distance-learning of mathematics, as it enables students to practice key techniques from home whilst receiving immediate feedback on their answers. Students can attempt different randomised variants of questions to support their learning and development. Execution Figure: A typical OU STACK question. STACK was first used in the curriculum in 2014 with the launch of a new introductory calculus module: MST124 \"Essential Mathematics I\", which is currently studied by approximately 2,800 students per year. Since then, STACK has been taken up by many modules at all levels. The main use is for formative \u201cpractice quizzes\u201d allowing students to practice the important techniques taught. At lower levels, it is also used for summative assignments, which both encourage students to use the formative quizzes to prepare for the assignment and practice their mathematics, and help students keep on pace with their study by providing deadlines. At the postgraduate level, a series of linked-STACK questions has been developed to guide students through more complex mathematical arguments in the calculus of variations [1]. The School of Mathematics and Statistics have been supporting colleagues in the School of Engineering and Innovation who use STACK to support their teaching of mathematically-based topics. The School is also using STACK to support students between formal module study, and in preparation for study as a key component of online \u201cRevise and Refresh\u201d support materials. STACK is currently used in at least 10 modules providing at total of 330 CATS credits and reaching over 6,500 students annually. Over one million STACK questions are answered by students each year, which is approximately 18% of all quiz questions answered by OU students. Server STACK is supported by the University Information Technology department as part of the Moodle installation. This consists of 11 load-shared Apache Web Servers supported by 2 MaximaPool servers to service the use of Maxima by STACK. Despite the high level of use, STACK has been robust in performance with no unplanned service outages during the period of use. All question authors are strongly encouraged to include Question tests as part of each STACK question, which helps ensure that the integrity of the questions is maintained over time. Before each STACK upgrade, IT checks the question tests of all STACK questions to ensure none are affected by the upgrade. If any tests fail, the questions are corrected by the appropriate module staff before the upgrade is applied to the live system. Feedback Students\u2019 engagement with the quizzes is often demonstrated by comments posted in online forums, for example questioning details of the worked solution provided. Students are often not content with just being able to answer every question in a quiz, but continue to try to correctly answer the quiz in the minimum time. Student feedback on the use of STACK quizzes has been positive, with many choosing to praise them in the unprompted open comments of the university module feedback survey. Conversely, negative comments are received where a module does not have STACK quizzes. Typical student comments include the following: I do value the practice quizzes because you do get practice, the feedback explanations are very good and detailed. [I] have done two runs of the practice quiz which has made a big difference for me and will become something I will be doing much more as [it] helps so much. I have been doing the practice quiz every morning now for 2 weeks ... I managed 100% on one of the quizzes and over 90% now on all of them so my confidence level is going up! The practice quizzes were excellent and I think absolutely essential for consolidating your understanding of the subject. What's Next The School currently plans to introduce STACK quizzes into additional modules as they are updated. Future plans include extending the use of STACK to further, higher level modules and to expand the use of STACK to support students in checking their preparedness for the study of various modules. References [1] T. W. Lowe and B. M. Mestel. Using STACK to support student learning at masters level: a case study. Teaching Mathematics and its Applications: An International Journal of the IMA, 2019. Technical Integration of STACK Into ILIAS STACK for Engineering Mathematics and the Abacus Material Bank","title":"STACK at Scale: The Open University"},{"location":"CaseStudies/2019/StackAtScale/#stack-at-scale-the-open-university","text":"","title":"STACK at Scale: The Open University"},{"location":"CaseStudies/2019/StackAtScale/#the-open-university","text":"Tim Lowe, School of Mathematics and Statistics, Tim Hunt, Information Technology.","title":"The Open University."},{"location":"CaseStudies/2019/StackAtScale/#introduction","text":"Figure: The Open University. The Open University is the UK\u2019s largest academic institution. In 2017/18 there were approximately 175,000 students studying with the University, mainly part time, making approximately 65,000 full-time equivalent students. Students combine their study with work, family, caring and other responsibilities. Students study from home, at a distance, guided by the University\u2019s Moodle-based VLE and using a combination of online and printed materials. Students are supported by a tutor who provides individual support to a group of typically 20 students and usually offers a combination of face-to-face and online tutorial support. The School of Mathematics and Statistics offers a number of undergraduate qualifications in mathematics (with a total intake of approximately 1300 each year) and a taught MSc, which is the largest such course in the UK. In addition, students throughout the University can take one or more mathematics modules in support of their main subject of study. There are approximately 13,000 student-module combinations within mathematics and statistics each year. STACK is an ideal tool to support the distance-learning of mathematics, as it enables students to practice key techniques from home whilst receiving immediate feedback on their answers. Students can attempt different randomised variants of questions to support their learning and development.","title":"Introduction"},{"location":"CaseStudies/2019/StackAtScale/#execution","text":"Figure: A typical OU STACK question. STACK was first used in the curriculum in 2014 with the launch of a new introductory calculus module: MST124 \"Essential Mathematics I\", which is currently studied by approximately 2,800 students per year. Since then, STACK has been taken up by many modules at all levels. The main use is for formative \u201cpractice quizzes\u201d allowing students to practice the important techniques taught. At lower levels, it is also used for summative assignments, which both encourage students to use the formative quizzes to prepare for the assignment and practice their mathematics, and help students keep on pace with their study by providing deadlines. At the postgraduate level, a series of linked-STACK questions has been developed to guide students through more complex mathematical arguments in the calculus of variations [1]. The School of Mathematics and Statistics have been supporting colleagues in the School of Engineering and Innovation who use STACK to support their teaching of mathematically-based topics. The School is also using STACK to support students between formal module study, and in preparation for study as a key component of online \u201cRevise and Refresh\u201d support materials. STACK is currently used in at least 10 modules providing at total of 330 CATS credits and reaching over 6,500 students annually. Over one million STACK questions are answered by students each year, which is approximately 18% of all quiz questions answered by OU students.","title":"Execution"},{"location":"CaseStudies/2019/StackAtScale/#server","text":"STACK is supported by the University Information Technology department as part of the Moodle installation. This consists of 11 load-shared Apache Web Servers supported by 2 MaximaPool servers to service the use of Maxima by STACK. Despite the high level of use, STACK has been robust in performance with no unplanned service outages during the period of use. All question authors are strongly encouraged to include Question tests as part of each STACK question, which helps ensure that the integrity of the questions is maintained over time. Before each STACK upgrade, IT checks the question tests of all STACK questions to ensure none are affected by the upgrade. If any tests fail, the questions are corrected by the appropriate module staff before the upgrade is applied to the live system.","title":"Server"},{"location":"CaseStudies/2019/StackAtScale/#feedback","text":"Students\u2019 engagement with the quizzes is often demonstrated by comments posted in online forums, for example questioning details of the worked solution provided. Students are often not content with just being able to answer every question in a quiz, but continue to try to correctly answer the quiz in the minimum time. Student feedback on the use of STACK quizzes has been positive, with many choosing to praise them in the unprompted open comments of the university module feedback survey. Conversely, negative comments are received where a module does not have STACK quizzes. Typical student comments include the following: I do value the practice quizzes because you do get practice, the feedback explanations are very good and detailed. [I] have done two runs of the practice quiz which has made a big difference for me and will become something I will be doing much more as [it] helps so much. I have been doing the practice quiz every morning now for 2 weeks ... I managed 100% on one of the quizzes and over 90% now on all of them so my confidence level is going up! The practice quizzes were excellent and I think absolutely essential for consolidating your understanding of the subject.","title":"Feedback"},{"location":"CaseStudies/2019/StackAtScale/#whats-next","text":"The School currently plans to introduce STACK quizzes into additional modules as they are updated. Future plans include extending the use of STACK to further, higher level modules and to expand the use of STACK to support students in checking their preparedness for the study of various modules.","title":"What's Next"},{"location":"CaseStudies/2019/StackAtScale/#references","text":"[1] T. W. Lowe and B. M. Mestel. Using STACK to support student learning at masters level: a case study. Teaching Mathematics and its Applications: An International Journal of the IMA, 2019. Technical Integration of STACK Into ILIAS STACK for Engineering Mathematics and the Abacus Material Bank","title":"References"},{"location":"CaseStudies/2019/optes/","text":"optes: Optimising Self-study With STACK DHBW Mannheim Miriam Weigel, Katja Derr, Reinhold H\u00fcbl Abstract The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills for their first year at university. The tests were developed and maintained at DHBW Mannheim. Here, students take a diagnostic test, and based on their results are given access to various learning modules, comprising text, graphs, animations, examples and exercises. An analysis of data gathered from the first evaluation phase of the project shows that the pre-course is effective at bridging gaps in school knowledge: at-risk students who end up scoring highly in the pre-course show improved performance in their first year mathematics courses. Introduction Students entering higher education are a diverse group and many students have considerable gaps in school knowledge, putting additional pressure on their first year at university. This particularly applies to mathematics, as basic skills in this subject are considered a prerequisite to successfully complete a course in STEM subjects. As a consequence, many universities provide preparatory courses in mathematics, either face-to-face, web-based, or in blended learning scenarios. The joint research project optes , funded by the German Federal Ministry of Education and Research (BMBF), develops and evaluates learning materials and tools that help students \u201crefresh\u201d their basic knowledge in mathematics and support the development of learning strategies. optes stands for \u201cOptimierung der Selbststudiumsphase\u201d, which translates to \"optimisation of the self-study phase\". Over the course of eight years, optes developed a comprehensive web-based pre-course consisting of diagnostic tests, learning modules and concepts for web-based student support, and tested it at the participating universities. The partner universities include Baden-Wuerttemberg Cooperative State University (DHBW) Karlsruhe, DHBW Mannheim, DHBW Mosbach, University of Applied Sciences and Arts Ostwestfalen-Lippe, Universit\u00e4t Hamburg; Cooperating universities: Julius-Maximilians-Universit\u00e4t W\u00fcrzburg, University of Education Heidelberg. Why Use STACK? The project put a strong focus on the development of self-tests that enable learners to apply their knowledge and provide them with meaningful feedback. This required a sophisticated CAA system, especially one that allowed students to enter an algebraic input. Since optes results are published under Creative Commons or General Public licenses, it was also important that the system was open source. To find the most suitable CAA system, the researchers analysed and compared many existing mathematical tools and in 2013, STACK was chosen. One of the reasons for choosing STACK, is that STACK uses the Learning Management System (LMS) Moodle and the Computer Algebra System (CAS) Maxima, both of which are supported by large communities. This gave the researchers confidence that STACK would also be used and developed further. Additionally, STACK is flexible enough to allow researchers to design very different types of mathematical problems. The only barrier was that STACK was not available for the LMS ILIAS at the time, a system widely used in Germany. However a crowd funding initiative was successful in gathering enough funds to implement STACK into ILIAS. Execution The partner university DHBW Mannheim was responsible for the development of tests and self-assessments. Here, a very basic version of the pre-course was implemented in 2013, and based on repeated evaluations, the different tests and learning modules were successively built and improved upon [2]. While some learning resources already existed in the form of printed scripts and paper versions of tests, the complete course material had to be rewritten and typed into ILIAS. In 2019, the course held ten interactive learning modules, with more than 1500 mathematics test items, 140 of which use STACK. Figure 1 shows an overview of the course structure as executed at DHBW Mannheim since 2014. The programme runs in the months leading up to a new semester, and starts with a diagnostic self-test covering the entire pre-course's syllabus. See also recommendations by SEFI mathematics working group [6], and cosh [1]. Depending on their diagnostics test results, students may access the different learning modules. Each course provides text, graphs, animations, examples and exercises, and at the end of each module, students can take a subject-related test consisting of 10 to 15 randomised questions. Students who want additional support can enrol in e-tutored courses, where their learning process is structured and monitored by e-tutors. Students can then discuss problems and test results with peers and e-tutors, and are required to upload completed exercise sheets. During induction week, all participating first year students take a final test at the University\u2019s computer laboratories. Since 2014, more than 2800 students have participated in the diagnostic pre-test and the pre-course at DHBW Mannheim. This corresponds to approximately 560 students per year, which is around 80% of the cohort. Figure: Course design at DHBW Mannheim. While the diagnostic self-test aims at informing learners of their level of knowledge in relation to the curriculum, the self-tests provided in the ten different courses are designed to encourage learners to independently practice their skills. Question Construction Figure 2 shows an example of an optes question in ILIAS. Students can click the checkmark next to the input box to have their answers validated by the system. On top of the question, the student can click to pop-out an explanation of the input syntax. The question is graded by clicking on \u201cR\u00fcckmeldung anfordern\u201d, which means \"Request feedback\". In this example, the student is asked to give an example of a function with three given zeroes. There are no other constraints, and in particular the function can also have more zeroes. The given zeroes are randomly generated, so the student can restart the test to try a variant of the problem with different constants. Figure: An optes question about giving an example of a function with given zeroes. optes questions focus on providing good feedback to students [8]. Feedback incorporates partial marks, if the student for example entered a function with only one or two of the given zeroes, and visuals, by for example graphing the student's answer (in red) against a correct answer (in blue). The student is also shown the value of their function at the three given points and given a model solution. optes questions are great examples of effective use of STACK's feedback features. Figure: Feedback to the example question shown above. Results The major goal of the optes project was to improve students\u2018 self-study abilities in mathematics related subjects. Using data collected from the first evaluations phase of the project, the researchers studied the influence of taking the pre-course on different variables. They found that the biggest factor in study success was a student's previous knowledge and secondary school scores. However, they also found that the pre-course could be very effective at improving first-year performance. Of the students whose performance were at risk, those who scored highly in the pre-course also did better in their first year of study. These were the students with poor prior study success or little domain-related knowledge. Self-test engagement was also found to have significance, as they were related to both pre-course gains and first-year performance. Challenges A major advantage of learning management systems is their ability to provide automated feedback to students. Instructors are hence relieved from the load of marking hundreds of exercises, and students appreciate the immediate response of the system. However, writing feedback for web-based mathematical problems is time-consuming, and these efforts may grow exponentially when the questions have multiple correct answers. To help soften this burden, it is important to share STACK questions, not only across pre-course projects but also across universities and e-learning platforms. Enablers A major enabler for the project was the initiative to integrate STACK into ILIAS. If this crowd funding initiative had failed, optes may have had to choose a less suited CAA system. Furthermore, a lot of institutional support enabled this project. While all resources developed by optes are Open Educational Resources (OER), the implementation of the learning material at third party universities or educational institutions demanded staff and technical infrastructure to install ILIAS and STACK. Staff and technical support helped administer the pre-course and adapt the learning material to each university\u2019s needs. Furthermore, the e-tutor system was enabled by lecturers and older students who took the time to learn to use STACK so they could help pre-course participants as e-tutors. What's Next? Since 2019, the rollout of optes to other universities and institutions has begun, and as more and more lecturers use the optes resources, the STACK community in Germany continues to grow. This community is largely represented by the working group \"Mathe digital\". Lecturers are encouraged to develop and contribute their own questions, resulting in a growing and improving database of available STACK questions. The researchers continue to evaluate the data from the project. When this analysis is finished, it will be possible to better identify the strengths and weaknesses of the course structure. Like all projects funded by the German BMBF programme \"Quality pact for teaching\", optes will be finished by the end of 2020. The developed concepts and course material, however, will be used and developed further at the optes partner universities and at all universities and institutions that share the material. Future plans include incorporating adaptive testing and expanding the work to other subjects and topics, such as mathematics for business and psychology courses. References [1] COSH Cooperation Schule Hochschule. Mindestanforderungskatalog mathematik. 2014. [2] K. Derr. Identifying consistent variables in a heterogeneous data set. Electronic Journal of e-Learning EJEL, 15(1):82-93, 2017. [3] K. Derr, R. Hubl, and M. Z. Ahmed. Prior knowledge in mathematics and study success in engineering. informational value of learner data collected from a web-based pre-course. European Journal of Engineering Education, 10(3):1-16, 2018. [4] C. J. Sangwin and I. Jones. Asymmetry in student achievement on multiple choice and constructed response items in reversible mathematics processes. Educational Studies in Mathematics, 94:205-222, 2017. [5] B. Alpers. A framework for mathematics curricula in engineering education. 2013. [6] M. Weigel, K. Derr, R. H\u007fubl, and T. Podgayetskaya. Stack-aufgaben im formativen eassessment: Einsatzmoglichkeiten des feedbacks. Zenodo, 2019. [7] M. Weigel, K. Derr, R. H\u007fubl, E. Mechelke-Schwede, and T. Podgayetskaya. Inhaltliche und technische aspekte des automatisierten feedback. einsatz des fragetyps stack im formativen eassessment. Beitrage zum Mathematikunterricht 2017, 1185-1192, 2017. Innovating Education in Maseno, Kenya Technical Integration of STACK Into ILIAS","title":"optes: Optimising Self-study With STACK"},{"location":"CaseStudies/2019/optes/#optes-optimising-self-study-with-stack","text":"","title":"optes: Optimising Self-study With STACK"},{"location":"CaseStudies/2019/optes/#dhbw-mannheim","text":"Miriam Weigel, Katja Derr, Reinhold H\u00fcbl","title":"DHBW Mannheim"},{"location":"CaseStudies/2019/optes/#abstract","text":"The optes project uses STACK in their pre-course, designed to help students improve their self-studying skills for their first year at university. The tests were developed and maintained at DHBW Mannheim. Here, students take a diagnostic test, and based on their results are given access to various learning modules, comprising text, graphs, animations, examples and exercises. An analysis of data gathered from the first evaluation phase of the project shows that the pre-course is effective at bridging gaps in school knowledge: at-risk students who end up scoring highly in the pre-course show improved performance in their first year mathematics courses.","title":"Abstract"},{"location":"CaseStudies/2019/optes/#introduction","text":"Students entering higher education are a diverse group and many students have considerable gaps in school knowledge, putting additional pressure on their first year at university. This particularly applies to mathematics, as basic skills in this subject are considered a prerequisite to successfully complete a course in STEM subjects. As a consequence, many universities provide preparatory courses in mathematics, either face-to-face, web-based, or in blended learning scenarios. The joint research project optes , funded by the German Federal Ministry of Education and Research (BMBF), develops and evaluates learning materials and tools that help students \u201crefresh\u201d their basic knowledge in mathematics and support the development of learning strategies. optes stands for \u201cOptimierung der Selbststudiumsphase\u201d, which translates to \"optimisation of the self-study phase\". Over the course of eight years, optes developed a comprehensive web-based pre-course consisting of diagnostic tests, learning modules and concepts for web-based student support, and tested it at the participating universities. The partner universities include Baden-Wuerttemberg Cooperative State University (DHBW) Karlsruhe, DHBW Mannheim, DHBW Mosbach, University of Applied Sciences and Arts Ostwestfalen-Lippe, Universit\u00e4t Hamburg; Cooperating universities: Julius-Maximilians-Universit\u00e4t W\u00fcrzburg, University of Education Heidelberg.","title":"Introduction"},{"location":"CaseStudies/2019/optes/#why-use-stack","text":"The project put a strong focus on the development of self-tests that enable learners to apply their knowledge and provide them with meaningful feedback. This required a sophisticated CAA system, especially one that allowed students to enter an algebraic input. Since optes results are published under Creative Commons or General Public licenses, it was also important that the system was open source. To find the most suitable CAA system, the researchers analysed and compared many existing mathematical tools and in 2013, STACK was chosen. One of the reasons for choosing STACK, is that STACK uses the Learning Management System (LMS) Moodle and the Computer Algebra System (CAS) Maxima, both of which are supported by large communities. This gave the researchers confidence that STACK would also be used and developed further. Additionally, STACK is flexible enough to allow researchers to design very different types of mathematical problems. The only barrier was that STACK was not available for the LMS ILIAS at the time, a system widely used in Germany. However a crowd funding initiative was successful in gathering enough funds to implement STACK into ILIAS.","title":"Why Use STACK?"},{"location":"CaseStudies/2019/optes/#execution","text":"The partner university DHBW Mannheim was responsible for the development of tests and self-assessments. Here, a very basic version of the pre-course was implemented in 2013, and based on repeated evaluations, the different tests and learning modules were successively built and improved upon [2]. While some learning resources already existed in the form of printed scripts and paper versions of tests, the complete course material had to be rewritten and typed into ILIAS. In 2019, the course held ten interactive learning modules, with more than 1500 mathematics test items, 140 of which use STACK. Figure 1 shows an overview of the course structure as executed at DHBW Mannheim since 2014. The programme runs in the months leading up to a new semester, and starts with a diagnostic self-test covering the entire pre-course's syllabus. See also recommendations by SEFI mathematics working group [6], and cosh [1]. Depending on their diagnostics test results, students may access the different learning modules. Each course provides text, graphs, animations, examples and exercises, and at the end of each module, students can take a subject-related test consisting of 10 to 15 randomised questions. Students who want additional support can enrol in e-tutored courses, where their learning process is structured and monitored by e-tutors. Students can then discuss problems and test results with peers and e-tutors, and are required to upload completed exercise sheets. During induction week, all participating first year students take a final test at the University\u2019s computer laboratories. Since 2014, more than 2800 students have participated in the diagnostic pre-test and the pre-course at DHBW Mannheim. This corresponds to approximately 560 students per year, which is around 80% of the cohort. Figure: Course design at DHBW Mannheim. While the diagnostic self-test aims at informing learners of their level of knowledge in relation to the curriculum, the self-tests provided in the ten different courses are designed to encourage learners to independently practice their skills.","title":"Execution"},{"location":"CaseStudies/2019/optes/#question-construction","text":"Figure 2 shows an example of an optes question in ILIAS. Students can click the checkmark next to the input box to have their answers validated by the system. On top of the question, the student can click to pop-out an explanation of the input syntax. The question is graded by clicking on \u201cR\u00fcckmeldung anfordern\u201d, which means \"Request feedback\". In this example, the student is asked to give an example of a function with three given zeroes. There are no other constraints, and in particular the function can also have more zeroes. The given zeroes are randomly generated, so the student can restart the test to try a variant of the problem with different constants. Figure: An optes question about giving an example of a function with given zeroes. optes questions focus on providing good feedback to students [8]. Feedback incorporates partial marks, if the student for example entered a function with only one or two of the given zeroes, and visuals, by for example graphing the student's answer (in red) against a correct answer (in blue). The student is also shown the value of their function at the three given points and given a model solution. optes questions are great examples of effective use of STACK's feedback features. Figure: Feedback to the example question shown above.","title":"Question Construction"},{"location":"CaseStudies/2019/optes/#results","text":"The major goal of the optes project was to improve students\u2018 self-study abilities in mathematics related subjects. Using data collected from the first evaluations phase of the project, the researchers studied the influence of taking the pre-course on different variables. They found that the biggest factor in study success was a student's previous knowledge and secondary school scores. However, they also found that the pre-course could be very effective at improving first-year performance. Of the students whose performance were at risk, those who scored highly in the pre-course also did better in their first year of study. These were the students with poor prior study success or little domain-related knowledge. Self-test engagement was also found to have significance, as they were related to both pre-course gains and first-year performance.","title":"Results"},{"location":"CaseStudies/2019/optes/#challenges","text":"A major advantage of learning management systems is their ability to provide automated feedback to students. Instructors are hence relieved from the load of marking hundreds of exercises, and students appreciate the immediate response of the system. However, writing feedback for web-based mathematical problems is time-consuming, and these efforts may grow exponentially when the questions have multiple correct answers. To help soften this burden, it is important to share STACK questions, not only across pre-course projects but also across universities and e-learning platforms.","title":"Challenges"},{"location":"CaseStudies/2019/optes/#enablers","text":"A major enabler for the project was the initiative to integrate STACK into ILIAS. If this crowd funding initiative had failed, optes may have had to choose a less suited CAA system. Furthermore, a lot of institutional support enabled this project. While all resources developed by optes are Open Educational Resources (OER), the implementation of the learning material at third party universities or educational institutions demanded staff and technical infrastructure to install ILIAS and STACK. Staff and technical support helped administer the pre-course and adapt the learning material to each university\u2019s needs. Furthermore, the e-tutor system was enabled by lecturers and older students who took the time to learn to use STACK so they could help pre-course participants as e-tutors.","title":"Enablers"},{"location":"CaseStudies/2019/optes/#whats-next","text":"Since 2019, the rollout of optes to other universities and institutions has begun, and as more and more lecturers use the optes resources, the STACK community in Germany continues to grow. This community is largely represented by the working group \"Mathe digital\". Lecturers are encouraged to develop and contribute their own questions, resulting in a growing and improving database of available STACK questions. The researchers continue to evaluate the data from the project. When this analysis is finished, it will be possible to better identify the strengths and weaknesses of the course structure. Like all projects funded by the German BMBF programme \"Quality pact for teaching\", optes will be finished by the end of 2020. The developed concepts and course material, however, will be used and developed further at the optes partner universities and at all universities and institutions that share the material. Future plans include incorporating adaptive testing and expanding the work to other subjects and topics, such as mathematics for business and psychology courses.","title":"What's Next?"},{"location":"CaseStudies/2019/optes/#references","text":"[1] COSH Cooperation Schule Hochschule. Mindestanforderungskatalog mathematik. 2014. [2] K. Derr. Identifying consistent variables in a heterogeneous data set. Electronic Journal of e-Learning EJEL, 15(1):82-93, 2017. [3] K. Derr, R. Hubl, and M. Z. Ahmed. Prior knowledge in mathematics and study success in engineering. informational value of learner data collected from a web-based pre-course. European Journal of Engineering Education, 10(3):1-16, 2018. [4] C. J. Sangwin and I. Jones. Asymmetry in student achievement on multiple choice and constructed response items in reversible mathematics processes. Educational Studies in Mathematics, 94:205-222, 2017. [5] B. Alpers. A framework for mathematics curricula in engineering education. 2013. [6] M. Weigel, K. Derr, R. H\u007fubl, and T. Podgayetskaya. Stack-aufgaben im formativen eassessment: Einsatzmoglichkeiten des feedbacks. Zenodo, 2019. [7] M. Weigel, K. Derr, R. H\u007fubl, E. Mechelke-Schwede, and T. Podgayetskaya. Inhaltliche und technische aspekte des automatisierten feedback. einsatz des fragetyps stack im formativen eassessment. Beitrage zum Mathematikunterricht 2017, 1185-1192, 2017. Innovating Education in Maseno, Kenya Technical Integration of STACK Into ILIAS","title":"References"},{"location":"Legal/Accessibility/","text":"Accessibility We believe online assessment should be available and accessible to all. We have taken steps to comply with the Web Content Accessibility Guidelines (WCAG) 2.1 on www.stack-assessment.org (\"the website\") at most of level AA requirements. This statement covers the website, and does not cover the STACK interface for teachers and students. Steps taken The website functions at 200% zoom, is responsive and usable on most common browsers and resolutions; browsers tested on: Chrome, Firefox, Safari, Edge, Internet Explorer, resolutions tested on: common resolutions for laptop, tablet and mobile, can be navigated solely by keyboard, functions with most common screen readers, ensures all non-text elements have alternative text, has closed captions available with all videos, never uses colour as the sole means of conveying information, ensures a colour contrast ratio of 4:5:1 throughout the website. Steps not yet taken The language of the website is often quite technical. The user map on /CaseStudies/Overview is not navigable by keyboard. The documentation website docs.stack-assessment.org has not yet been tested for accessibility. Internet Explorer 9 and down are not supported. For comments or suggestions regarding to accessibility, please email Chris Sangwin at C.J.Sangwin@ed.ac.uk","title":"Accessibility"},{"location":"Legal/Accessibility/#accessibility","text":"We believe online assessment should be available and accessible to all. We have taken steps to comply with the Web Content Accessibility Guidelines (WCAG) 2.1 on www.stack-assessment.org (\"the website\") at most of level AA requirements. This statement covers the website, and does not cover the STACK interface for teachers and students.","title":"Accessibility"},{"location":"Legal/Accessibility/#steps-taken","text":"The website functions at 200% zoom, is responsive and usable on most common browsers and resolutions; browsers tested on: Chrome, Firefox, Safari, Edge, Internet Explorer, resolutions tested on: common resolutions for laptop, tablet and mobile, can be navigated solely by keyboard, functions with most common screen readers, ensures all non-text elements have alternative text, has closed captions available with all videos, never uses colour as the sole means of conveying information, ensures a colour contrast ratio of 4:5:1 throughout the website.","title":"Steps taken"},{"location":"Legal/Accessibility/#steps-not-yet-taken","text":"The language of the website is often quite technical. The user map on /CaseStudies/Overview is not navigable by keyboard. The documentation website docs.stack-assessment.org has not yet been tested for accessibility. Internet Explorer 9 and down are not supported. For comments or suggestions regarding to accessibility, please email Chris Sangwin at C.J.Sangwin@ed.ac.uk","title":"Steps not yet taken"},{"location":"Legal/Licenses/","text":"Licenses The following are licenses for STACK, stack-assessment.org and docs.stack-assessment.org (\"the website\"). STACK STACK is licensed under the GNU General Public License Version 3. GitHub Pages The website is hosted on GitHub pages . Please see the GitHub terms of service . MkDocs The website is built with MkDocs , licensed under a BSD license. mdx_math The website uses the mdx_math markdown compiler . python-markdown-math license. Bootstrap stack-assessment.org uses Bootstrap , licensed under a MIT License. Bootstrap MkDocs Theme Bootstrap is integrated into MkDocs using the mkdocs-bootstrap theme, licensed under a BSD 2-Clause \"Simplified\" License. Material docs.stack-assessment.org uses the Material theme, licensed under a MIT License.","title":"Licenses"},{"location":"Legal/Licenses/#licenses","text":"The following are licenses for STACK, stack-assessment.org and docs.stack-assessment.org (\"the website\").","title":"Licenses"},{"location":"Legal/Licenses/#stack","text":"STACK is licensed under the GNU General Public License Version 3.","title":"STACK"},{"location":"Legal/Licenses/#github-pages","text":"The website is hosted on GitHub pages . Please see the GitHub terms of service .","title":"GitHub Pages"},{"location":"Legal/Licenses/#mkdocs","text":"The website is built with MkDocs , licensed under a BSD license.","title":"MkDocs"},{"location":"Legal/Licenses/#mdx_math","text":"The website uses the mdx_math markdown compiler . python-markdown-math license.","title":"mdx_math"},{"location":"Legal/Licenses/#bootstrap","text":"stack-assessment.org uses Bootstrap , licensed under a MIT License.","title":"Bootstrap"},{"location":"Legal/Licenses/#bootstrap-mkdocs-theme","text":"Bootstrap is integrated into MkDocs using the mkdocs-bootstrap theme, licensed under a BSD 2-Clause \"Simplified\" License.","title":"Bootstrap MkDocs Theme"},{"location":"Legal/Licenses/#material","text":"docs.stack-assessment.org uses the Material theme, licensed under a MIT License.","title":"Material"},{"location":"Legal/PrivacyStatement/","text":"Privacy Statement This statement was last revised on 11/8/2020. How we collect your data This website is hosted on GitHub Pages. GitHub may collect User Personal Information from visitors to this website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of the Website and the Service. Please see GitHub's privacy statement for information on how your data is used and stored by GitHub. We do not otherwise collect any personal information about you when you visit this website. Privacy policies of other websites This statement refers only to this website (www.stack-assessment.org), and not to any other STACK websites, or any third party sites linked to on this website. You are encouraged to review privacy statements on other websites when you visit them. Changes to our privacy policy The date of the latest revision is shown at the top of the page. We may change this privacy statement at any time and for any reason. You are encouraged to regularly review this statement. How to contact us If you have questions about our privacy policy, please email Professor Chris Sangwin at C.J.Sangwin@ed.ac.uk .","title":"Privacy Statement"},{"location":"Legal/PrivacyStatement/#privacy-statement","text":"This statement was last revised on 11/8/2020.","title":"Privacy Statement"},{"location":"Legal/PrivacyStatement/#how-we-collect-your-data","text":"This website is hosted on GitHub Pages. GitHub may collect User Personal Information from visitors to this website, including logs of visitor IP addresses, to comply with legal obligations, and to maintain the security and integrity of the Website and the Service. Please see GitHub's privacy statement for information on how your data is used and stored by GitHub. We do not otherwise collect any personal information about you when you visit this website.","title":"How we collect your data"},{"location":"Legal/PrivacyStatement/#privacy-policies-of-other-websites","text":"This statement refers only to this website (www.stack-assessment.org), and not to any other STACK websites, or any third party sites linked to on this website. You are encouraged to review privacy statements on other websites when you visit them.","title":"Privacy policies of other websites"},{"location":"Legal/PrivacyStatement/#changes-to-our-privacy-policy","text":"The date of the latest revision is shown at the top of the page. We may change this privacy statement at any time and for any reason. You are encouraged to regularly review this statement.","title":"Changes to our privacy policy"},{"location":"Legal/PrivacyStatement/#how-to-contact-us","text":"If you have questions about our privacy policy, please email Professor Chris Sangwin at C.J.Sangwin@ed.ac.uk .","title":"How to contact us"}]}